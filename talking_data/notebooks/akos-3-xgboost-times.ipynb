{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # pandas\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  XGBoost\n",
    "https://www.kaggle.com/tilii7/xgboost-simple-starter-more-features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akos/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#Importing Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.externals import joblib\n",
    "from sklearn import metrics\n",
    "import xgboost as xgb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../datasets/train1_30labels_withdaytimes.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>device_id</th>\n",
       "      <th>events_num</th>\n",
       "      <th>min_timestamp</th>\n",
       "      <th>max_timestamp</th>\n",
       "      <th>events_per_day</th>\n",
       "      <th>label_548</th>\n",
       "      <th>label_i_548</th>\n",
       "      <th>label_704</th>\n",
       "      <th>label_i_704</th>\n",
       "      <th>...</th>\n",
       "      <th>weekend_morning</th>\n",
       "      <th>weekend_daytime</th>\n",
       "      <th>weekend_evening</th>\n",
       "      <th>weekend_night</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>group</th>\n",
       "      <th>phone_brand</th>\n",
       "      <th>device_model</th>\n",
       "      <th>phone_brand_eng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-8076087639492063270</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>35</td>\n",
       "      <td>M32-38</td>\n",
       "      <td>小米</td>\n",
       "      <td>MI 2</td>\n",
       "      <td>Xiaomi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-2897161552818060146</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>35</td>\n",
       "      <td>M32-38</td>\n",
       "      <td>小米</td>\n",
       "      <td>MI 2</td>\n",
       "      <td>Xiaomi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-8260683887967679142</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-05-01 14:23:37</td>\n",
       "      <td>2016-05-01 14:23:37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>35</td>\n",
       "      <td>M32-38</td>\n",
       "      <td>小米</td>\n",
       "      <td>MI 2</td>\n",
       "      <td>Xiaomi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-4938849341048082022</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>30</td>\n",
       "      <td>M29-31</td>\n",
       "      <td>小米</td>\n",
       "      <td>红米note</td>\n",
       "      <td>Xiaomi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>245133531816851882</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>30</td>\n",
       "      <td>M29-31</td>\n",
       "      <td>小米</td>\n",
       "      <td>MI 3</td>\n",
       "      <td>Xiaomi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0            device_id  events_num        min_timestamp  \\\n",
       "0           0 -8076087639492063270           0                  NaN   \n",
       "1           1 -2897161552818060146           0                  NaN   \n",
       "2           2 -8260683887967679142           1  2016-05-01 14:23:37   \n",
       "3           3 -4938849341048082022           0                  NaN   \n",
       "4           4   245133531816851882           0                  NaN   \n",
       "\n",
       "         max_timestamp  events_per_day  label_548  label_i_548  label_704  \\\n",
       "0                  NaN             NaN          0            0          0   \n",
       "1                  NaN             NaN          0            0          0   \n",
       "2  2016-05-01 14:23:37             0.0          5           30          3   \n",
       "3                  NaN             NaN          0            0          0   \n",
       "4                  NaN             NaN          0            0          0   \n",
       "\n",
       "   label_i_704       ...         weekend_morning  weekend_daytime  \\\n",
       "0            0       ...                       0                0   \n",
       "1            0       ...                       0                0   \n",
       "2           24       ...                       0                1   \n",
       "3            0       ...                       0                0   \n",
       "4            0       ...                       0                0   \n",
       "\n",
       "   weekend_evening  weekend_night  gender  age   group  phone_brand  \\\n",
       "0                0              0       M   35  M32-38           小米   \n",
       "1                0              0       M   35  M32-38           小米   \n",
       "2                0              0       M   35  M32-38           小米   \n",
       "3                0              0       M   30  M29-31           小米   \n",
       "4                0              0       M   30  M29-31           小米   \n",
       "\n",
       "   device_model  phone_brand_eng  \n",
       "0          MI 2           Xiaomi  \n",
       "1          MI 2           Xiaomi  \n",
       "2          MI 2           Xiaomi  \n",
       "3        红米note           Xiaomi  \n",
       "4          MI 3           Xiaomi  \n",
       "\n",
       "[5 rows x 82 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   num_boost_round = 500\n",
    "    early_stopping_rounds = 20\n",
    "    test_size = 0.2\n",
    "\n",
    "    X_train, X_valid = train_test_split(train, test_size=test_size, random_state=random_state)\n",
    "    print('Length train:', len(X_train.index))\n",
    "    print('Length valid:', len(X_valid.index))\n",
    "    y_train = X_train[target]\n",
    "    y_valid = X_valid[target]\n",
    "    dtrain = xgb.DMatrix(X_train[features], y_train)\n",
    "    dvalid = xgb.DMatrix(X_valid[features], y_valid)\n",
    "\n",
    "    watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "    gbm = xgb.train(params, dtrain, num_boost_round, evals=watchlist, early_stopping_rounds=early_stopping_rounds, verbose_eval=True)\n",
    "\n",
    "    print(\"Validating...\")\n",
    "    check = gbm.predict(xgb.DMatrix(X_valid[features]), ntree_limit=gbm.best_iteration)\n",
    "    score = log_loss(y_valid.tolist(), check)\n",
    "\n",
    "    imp = get_importance(gbm, features)\n",
    "    print('Importance array: ', imp)\n",
    "\n",
    "    print(\"Predict test set...\")\n",
    "    test_prediction = gbm.predict(xgb.DMatrix(test[features]), ntree_limit=gbm.best_iteration)\n",
    "\n",
    "    print('Training time: {} minutes'.format(round((time.time() - start_time)/60, 2)))\n",
    "    return test_prediction.tolist(), score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor = pd.factorize(df_train['phone_brand_eng'])\n",
    "df_train.phone_brand_eng = factor[0]\n",
    "definitions_phone_brand_eng = factor[1]\n",
    "factor = pd.factorize(df_train['device_model'])\n",
    "df_train.device_model = factor[0]\n",
    "definitions_device_model = factor[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor = pd.factorize(df_train['group'])\n",
    "df_train.group = factor[0]\n",
    "definitions = factor[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "magyarazo_valtozok = []\n",
    "for m in df_train.columns:\n",
    "    if m not in ['Unnamed: 0', 'device_id', 'min_timestamp', 'max_timestamp','gender', 'age', 'group', 'phone_brand' ]:\n",
    "        magyarazo_valtozok += [m]\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_train[magyarazo_valtozok], df_train['group'], test_size=0.2,random_state=109) # 90% training and 10% test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akos/anaconda3/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(X_train, y_train)\n",
    "dvalid = xgb.DMatrix(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>device_id</th>\n",
       "      <th>events_num</th>\n",
       "      <th>min_timestamp</th>\n",
       "      <th>max_timestamp</th>\n",
       "      <th>events_per_day</th>\n",
       "      <th>label_548</th>\n",
       "      <th>label_i_548</th>\n",
       "      <th>label_704</th>\n",
       "      <th>label_i_704</th>\n",
       "      <th>...</th>\n",
       "      <th>weekend_morning</th>\n",
       "      <th>weekend_daytime</th>\n",
       "      <th>weekend_evening</th>\n",
       "      <th>weekend_night</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>group</th>\n",
       "      <th>phone_brand</th>\n",
       "      <th>device_model</th>\n",
       "      <th>phone_brand_eng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-8076087639492063270</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>小米</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-2897161552818060146</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>小米</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-8260683887967679142</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-05-01 14:23:37</td>\n",
       "      <td>2016-05-01 14:23:37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>小米</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-4938849341048082022</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>小米</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>245133531816851882</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>小米</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0            device_id  events_num        min_timestamp  \\\n",
       "0           0 -8076087639492063270           0                  NaN   \n",
       "1           1 -2897161552818060146           0                  NaN   \n",
       "2           2 -8260683887967679142           1  2016-05-01 14:23:37   \n",
       "3           3 -4938849341048082022           0                  NaN   \n",
       "4           4   245133531816851882           0                  NaN   \n",
       "\n",
       "         max_timestamp  events_per_day  label_548  label_i_548  label_704  \\\n",
       "0                  NaN             NaN          0            0          0   \n",
       "1                  NaN             NaN          0            0          0   \n",
       "2  2016-05-01 14:23:37             0.0          5           30          3   \n",
       "3                  NaN             NaN          0            0          0   \n",
       "4                  NaN             NaN          0            0          0   \n",
       "\n",
       "   label_i_704       ...         weekend_morning  weekend_daytime  \\\n",
       "0            0       ...                       0                0   \n",
       "1            0       ...                       0                0   \n",
       "2           24       ...                       0                1   \n",
       "3            0       ...                       0                0   \n",
       "4            0       ...                       0                0   \n",
       "\n",
       "   weekend_evening  weekend_night  gender  age  group  phone_brand  \\\n",
       "0                0              0       M   35      0           小米   \n",
       "1                0              0       M   35      0           小米   \n",
       "2                0              0       M   35      0           小米   \n",
       "3                0              0       M   30      1           小米   \n",
       "4                0              0       M   30      1           小米   \n",
       "\n",
       "   device_model  phone_brand_eng  \n",
       "0             0                0  \n",
       "1             0                0  \n",
       "2             0                0  \n",
       "3             1                0  \n",
       "4             2                0  \n",
       "\n",
       "[5 rows x 82 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb parameterek ... nem tudom, hogy mi hogy számít...\n",
    "\n",
    "eta = 0.025\n",
    "max_depth = 7\n",
    "subsample = 0.75\n",
    "colsample_bytree = 0.75\n",
    "random_state=123\n",
    "params = {\n",
    "        \"objective\": \"multi:softprob\",\n",
    "        \"num_class\": 12,\n",
    "        \"booster\" : \"gbtree\",\n",
    "        \"eval_metric\": \"mlogloss\",\n",
    "        \"eta\": eta,\n",
    "        \"max_depth\": max_depth,\n",
    "        \"subsample\": subsample,\n",
    "        \"colsample_bytree\": colsample_bytree,\n",
    "        \"silent\": 1,\n",
    "        \"seed\": random_state,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:2.47987\teval-mlogloss:2.48165\n",
      "Multiple eval metrics have been passed: 'eval-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until eval-mlogloss hasn't improved in 20 rounds.\n",
      "[1]\ttrain-mlogloss:2.47494\teval-mlogloss:2.47868\n",
      "[2]\ttrain-mlogloss:2.4702\teval-mlogloss:2.47585\n",
      "[3]\ttrain-mlogloss:2.46558\teval-mlogloss:2.47305\n",
      "[4]\ttrain-mlogloss:2.46099\teval-mlogloss:2.47037\n",
      "[5]\ttrain-mlogloss:2.45646\teval-mlogloss:2.46761\n",
      "[6]\ttrain-mlogloss:2.45201\teval-mlogloss:2.46501\n",
      "[7]\ttrain-mlogloss:2.44786\teval-mlogloss:2.46274\n",
      "[8]\ttrain-mlogloss:2.44364\teval-mlogloss:2.46029\n",
      "[9]\ttrain-mlogloss:2.43928\teval-mlogloss:2.45782\n",
      "[10]\ttrain-mlogloss:2.43511\teval-mlogloss:2.45545\n",
      "[11]\ttrain-mlogloss:2.43115\teval-mlogloss:2.45324\n",
      "[12]\ttrain-mlogloss:2.42727\teval-mlogloss:2.45102\n",
      "[13]\ttrain-mlogloss:2.42342\teval-mlogloss:2.44887\n",
      "[14]\ttrain-mlogloss:2.41984\teval-mlogloss:2.4469\n",
      "[15]\ttrain-mlogloss:2.41605\teval-mlogloss:2.44484\n",
      "[16]\ttrain-mlogloss:2.41234\teval-mlogloss:2.44286\n",
      "[17]\ttrain-mlogloss:2.40881\teval-mlogloss:2.441\n",
      "[18]\ttrain-mlogloss:2.40534\teval-mlogloss:2.43906\n",
      "[19]\ttrain-mlogloss:2.40196\teval-mlogloss:2.43731\n",
      "[20]\ttrain-mlogloss:2.39859\teval-mlogloss:2.43551\n",
      "[21]\ttrain-mlogloss:2.39514\teval-mlogloss:2.43375\n",
      "[22]\ttrain-mlogloss:2.39191\teval-mlogloss:2.43206\n",
      "[23]\ttrain-mlogloss:2.38873\teval-mlogloss:2.43036\n",
      "[24]\ttrain-mlogloss:2.38561\teval-mlogloss:2.42878\n",
      "[25]\ttrain-mlogloss:2.38253\teval-mlogloss:2.4272\n",
      "[26]\ttrain-mlogloss:2.37939\teval-mlogloss:2.42559\n",
      "[27]\ttrain-mlogloss:2.37642\teval-mlogloss:2.42423\n",
      "[28]\ttrain-mlogloss:2.37338\teval-mlogloss:2.42282\n",
      "[29]\ttrain-mlogloss:2.37047\teval-mlogloss:2.42142\n",
      "[30]\ttrain-mlogloss:2.36759\teval-mlogloss:2.42006\n",
      "[31]\ttrain-mlogloss:2.36471\teval-mlogloss:2.41872\n",
      "[32]\ttrain-mlogloss:2.36192\teval-mlogloss:2.41733\n",
      "[33]\ttrain-mlogloss:2.35924\teval-mlogloss:2.41619\n",
      "[34]\ttrain-mlogloss:2.35649\teval-mlogloss:2.4149\n",
      "[35]\ttrain-mlogloss:2.35386\teval-mlogloss:2.41386\n",
      "[36]\ttrain-mlogloss:2.35122\teval-mlogloss:2.41277\n",
      "[37]\ttrain-mlogloss:2.34856\teval-mlogloss:2.41155\n",
      "[38]\ttrain-mlogloss:2.34616\teval-mlogloss:2.41052\n",
      "[39]\ttrain-mlogloss:2.34349\teval-mlogloss:2.40939\n",
      "[40]\ttrain-mlogloss:2.34102\teval-mlogloss:2.40831\n",
      "[41]\ttrain-mlogloss:2.33866\teval-mlogloss:2.40733\n",
      "[42]\ttrain-mlogloss:2.33615\teval-mlogloss:2.4063\n",
      "[43]\ttrain-mlogloss:2.33372\teval-mlogloss:2.40526\n",
      "[44]\ttrain-mlogloss:2.33139\teval-mlogloss:2.40428\n",
      "[45]\ttrain-mlogloss:2.32907\teval-mlogloss:2.40337\n",
      "[46]\ttrain-mlogloss:2.32683\teval-mlogloss:2.40242\n",
      "[47]\ttrain-mlogloss:2.32461\teval-mlogloss:2.40148\n",
      "[48]\ttrain-mlogloss:2.32242\teval-mlogloss:2.40055\n",
      "[49]\ttrain-mlogloss:2.32011\teval-mlogloss:2.39961\n",
      "[50]\ttrain-mlogloss:2.31799\teval-mlogloss:2.39875\n",
      "[51]\ttrain-mlogloss:2.31579\teval-mlogloss:2.39792\n",
      "[52]\ttrain-mlogloss:2.31374\teval-mlogloss:2.39713\n",
      "[53]\ttrain-mlogloss:2.31168\teval-mlogloss:2.39636\n",
      "[54]\ttrain-mlogloss:2.30961\teval-mlogloss:2.39561\n",
      "[55]\ttrain-mlogloss:2.30752\teval-mlogloss:2.39491\n",
      "[56]\ttrain-mlogloss:2.30545\teval-mlogloss:2.39416\n",
      "[57]\ttrain-mlogloss:2.3035\teval-mlogloss:2.39345\n",
      "[58]\ttrain-mlogloss:2.3015\teval-mlogloss:2.39275\n",
      "[59]\ttrain-mlogloss:2.29956\teval-mlogloss:2.39208\n",
      "[60]\ttrain-mlogloss:2.29767\teval-mlogloss:2.39137\n",
      "[61]\ttrain-mlogloss:2.29584\teval-mlogloss:2.39072\n",
      "[62]\ttrain-mlogloss:2.29401\teval-mlogloss:2.39018\n",
      "[63]\ttrain-mlogloss:2.29209\teval-mlogloss:2.38951\n",
      "[64]\ttrain-mlogloss:2.29017\teval-mlogloss:2.38892\n",
      "[65]\ttrain-mlogloss:2.28821\teval-mlogloss:2.38824\n",
      "[66]\ttrain-mlogloss:2.28634\teval-mlogloss:2.38762\n",
      "[67]\ttrain-mlogloss:2.28457\teval-mlogloss:2.38705\n",
      "[68]\ttrain-mlogloss:2.28281\teval-mlogloss:2.38643\n",
      "[69]\ttrain-mlogloss:2.28114\teval-mlogloss:2.3859\n",
      "[70]\ttrain-mlogloss:2.27932\teval-mlogloss:2.38529\n",
      "[71]\ttrain-mlogloss:2.27761\teval-mlogloss:2.38478\n",
      "[72]\ttrain-mlogloss:2.27597\teval-mlogloss:2.38429\n",
      "[73]\ttrain-mlogloss:2.27422\teval-mlogloss:2.38375\n",
      "[74]\ttrain-mlogloss:2.27252\teval-mlogloss:2.38326\n",
      "[75]\ttrain-mlogloss:2.27095\teval-mlogloss:2.38277\n",
      "[76]\ttrain-mlogloss:2.26937\teval-mlogloss:2.38235\n",
      "[77]\ttrain-mlogloss:2.26778\teval-mlogloss:2.38191\n",
      "[78]\ttrain-mlogloss:2.2661\teval-mlogloss:2.38145\n",
      "[79]\ttrain-mlogloss:2.26446\teval-mlogloss:2.38101\n",
      "[80]\ttrain-mlogloss:2.26287\teval-mlogloss:2.38065\n",
      "[81]\ttrain-mlogloss:2.26133\teval-mlogloss:2.38028\n",
      "[82]\ttrain-mlogloss:2.25986\teval-mlogloss:2.37988\n",
      "[83]\ttrain-mlogloss:2.25836\teval-mlogloss:2.37948\n",
      "[84]\ttrain-mlogloss:2.2568\teval-mlogloss:2.37913\n",
      "[85]\ttrain-mlogloss:2.25531\teval-mlogloss:2.37877\n",
      "[86]\ttrain-mlogloss:2.25374\teval-mlogloss:2.37838\n",
      "[87]\ttrain-mlogloss:2.25225\teval-mlogloss:2.37803\n",
      "[88]\ttrain-mlogloss:2.25074\teval-mlogloss:2.37762\n",
      "[89]\ttrain-mlogloss:2.24924\teval-mlogloss:2.37725\n",
      "[90]\ttrain-mlogloss:2.2478\teval-mlogloss:2.37688\n",
      "[91]\ttrain-mlogloss:2.24632\teval-mlogloss:2.37653\n",
      "[92]\ttrain-mlogloss:2.24485\teval-mlogloss:2.37616\n",
      "[93]\ttrain-mlogloss:2.24345\teval-mlogloss:2.37581\n",
      "[94]\ttrain-mlogloss:2.24205\teval-mlogloss:2.37547\n",
      "[95]\ttrain-mlogloss:2.24063\teval-mlogloss:2.37519\n",
      "[96]\ttrain-mlogloss:2.23929\teval-mlogloss:2.37488\n",
      "[97]\ttrain-mlogloss:2.23784\teval-mlogloss:2.37451\n",
      "[98]\ttrain-mlogloss:2.23653\teval-mlogloss:2.37424\n",
      "[99]\ttrain-mlogloss:2.23503\teval-mlogloss:2.374\n",
      "[100]\ttrain-mlogloss:2.23365\teval-mlogloss:2.37364\n",
      "[101]\ttrain-mlogloss:2.23246\teval-mlogloss:2.37336\n",
      "[102]\ttrain-mlogloss:2.23115\teval-mlogloss:2.37302\n",
      "[103]\ttrain-mlogloss:2.22982\teval-mlogloss:2.37271\n",
      "[104]\ttrain-mlogloss:2.2286\teval-mlogloss:2.37238\n",
      "[105]\ttrain-mlogloss:2.22734\teval-mlogloss:2.37216\n",
      "[106]\ttrain-mlogloss:2.22602\teval-mlogloss:2.37195\n",
      "[107]\ttrain-mlogloss:2.22465\teval-mlogloss:2.37168\n",
      "[108]\ttrain-mlogloss:2.22334\teval-mlogloss:2.37139\n",
      "[109]\ttrain-mlogloss:2.222\teval-mlogloss:2.37116\n",
      "[110]\ttrain-mlogloss:2.22081\teval-mlogloss:2.3709\n",
      "[111]\ttrain-mlogloss:2.21951\teval-mlogloss:2.37064\n",
      "[112]\ttrain-mlogloss:2.21826\teval-mlogloss:2.37046\n",
      "[113]\ttrain-mlogloss:2.21716\teval-mlogloss:2.37028\n",
      "[114]\ttrain-mlogloss:2.21594\teval-mlogloss:2.37004\n",
      "[115]\ttrain-mlogloss:2.21474\teval-mlogloss:2.36985\n",
      "[116]\ttrain-mlogloss:2.21359\teval-mlogloss:2.3696\n",
      "[117]\ttrain-mlogloss:2.21251\teval-mlogloss:2.36942\n",
      "[118]\ttrain-mlogloss:2.21123\teval-mlogloss:2.36927\n",
      "[119]\ttrain-mlogloss:2.21\teval-mlogloss:2.36906\n",
      "[120]\ttrain-mlogloss:2.20886\teval-mlogloss:2.3689\n",
      "[121]\ttrain-mlogloss:2.20772\teval-mlogloss:2.36868\n",
      "[122]\ttrain-mlogloss:2.20662\teval-mlogloss:2.36844\n",
      "[123]\ttrain-mlogloss:2.20545\teval-mlogloss:2.36824\n",
      "[124]\ttrain-mlogloss:2.20438\teval-mlogloss:2.36805\n",
      "[125]\ttrain-mlogloss:2.20317\teval-mlogloss:2.36786\n",
      "[126]\ttrain-mlogloss:2.20208\teval-mlogloss:2.36769\n",
      "[127]\ttrain-mlogloss:2.20099\teval-mlogloss:2.36744\n",
      "[128]\ttrain-mlogloss:2.19988\teval-mlogloss:2.3673\n",
      "[129]\ttrain-mlogloss:2.19884\teval-mlogloss:2.36713\n",
      "[130]\ttrain-mlogloss:2.1978\teval-mlogloss:2.367\n",
      "[131]\ttrain-mlogloss:2.19678\teval-mlogloss:2.36679\n",
      "[132]\ttrain-mlogloss:2.19577\teval-mlogloss:2.36665\n",
      "[133]\ttrain-mlogloss:2.19473\teval-mlogloss:2.36649\n",
      "[134]\ttrain-mlogloss:2.19379\teval-mlogloss:2.36632\n",
      "[135]\ttrain-mlogloss:2.1928\teval-mlogloss:2.36616\n",
      "[136]\ttrain-mlogloss:2.19174\teval-mlogloss:2.36605\n",
      "[137]\ttrain-mlogloss:2.19071\teval-mlogloss:2.36586\n",
      "[138]\ttrain-mlogloss:2.18971\teval-mlogloss:2.36571\n",
      "[139]\ttrain-mlogloss:2.18855\teval-mlogloss:2.36554\n",
      "[140]\ttrain-mlogloss:2.1875\teval-mlogloss:2.36544\n",
      "[141]\ttrain-mlogloss:2.18647\teval-mlogloss:2.36531\n",
      "[142]\ttrain-mlogloss:2.18548\teval-mlogloss:2.36515\n",
      "[143]\ttrain-mlogloss:2.18455\teval-mlogloss:2.365\n",
      "[144]\ttrain-mlogloss:2.18365\teval-mlogloss:2.36489\n",
      "[145]\ttrain-mlogloss:2.1826\teval-mlogloss:2.36474\n",
      "[146]\ttrain-mlogloss:2.18172\teval-mlogloss:2.36464\n",
      "[147]\ttrain-mlogloss:2.18076\teval-mlogloss:2.36455\n",
      "[148]\ttrain-mlogloss:2.17986\teval-mlogloss:2.36439\n",
      "[149]\ttrain-mlogloss:2.179\teval-mlogloss:2.3643\n",
      "[150]\ttrain-mlogloss:2.17801\teval-mlogloss:2.36418\n",
      "[151]\ttrain-mlogloss:2.17705\teval-mlogloss:2.36404\n",
      "[152]\ttrain-mlogloss:2.17623\teval-mlogloss:2.36394\n",
      "[153]\ttrain-mlogloss:2.17525\teval-mlogloss:2.36381\n",
      "[154]\ttrain-mlogloss:2.17426\teval-mlogloss:2.3637\n",
      "[155]\ttrain-mlogloss:2.1733\teval-mlogloss:2.36363\n",
      "[156]\ttrain-mlogloss:2.17235\teval-mlogloss:2.36349\n",
      "[157]\ttrain-mlogloss:2.17139\teval-mlogloss:2.36343\n",
      "[158]\ttrain-mlogloss:2.17036\teval-mlogloss:2.36328\n",
      "[159]\ttrain-mlogloss:2.16954\teval-mlogloss:2.36322\n",
      "[160]\ttrain-mlogloss:2.16863\teval-mlogloss:2.36312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[161]\ttrain-mlogloss:2.16766\teval-mlogloss:2.36301\n",
      "[162]\ttrain-mlogloss:2.16687\teval-mlogloss:2.36291\n",
      "[163]\ttrain-mlogloss:2.16598\teval-mlogloss:2.36278\n",
      "[164]\ttrain-mlogloss:2.16522\teval-mlogloss:2.36265\n",
      "[165]\ttrain-mlogloss:2.16428\teval-mlogloss:2.36254\n",
      "[166]\ttrain-mlogloss:2.16338\teval-mlogloss:2.36253\n",
      "[167]\ttrain-mlogloss:2.16249\teval-mlogloss:2.36245\n",
      "[168]\ttrain-mlogloss:2.16166\teval-mlogloss:2.36236\n",
      "[169]\ttrain-mlogloss:2.16082\teval-mlogloss:2.36229\n",
      "[170]\ttrain-mlogloss:2.15992\teval-mlogloss:2.36221\n",
      "[171]\ttrain-mlogloss:2.15927\teval-mlogloss:2.36213\n",
      "[172]\ttrain-mlogloss:2.15854\teval-mlogloss:2.36207\n",
      "[173]\ttrain-mlogloss:2.15756\teval-mlogloss:2.36194\n",
      "[174]\ttrain-mlogloss:2.15666\teval-mlogloss:2.36184\n",
      "[175]\ttrain-mlogloss:2.15573\teval-mlogloss:2.3618\n",
      "[176]\ttrain-mlogloss:2.15481\teval-mlogloss:2.36167\n",
      "[177]\ttrain-mlogloss:2.15406\teval-mlogloss:2.36159\n",
      "[178]\ttrain-mlogloss:2.15315\teval-mlogloss:2.36148\n",
      "[179]\ttrain-mlogloss:2.15236\teval-mlogloss:2.36137\n",
      "[180]\ttrain-mlogloss:2.1515\teval-mlogloss:2.36124\n",
      "[181]\ttrain-mlogloss:2.15073\teval-mlogloss:2.36115\n",
      "[182]\ttrain-mlogloss:2.14993\teval-mlogloss:2.36107\n",
      "[183]\ttrain-mlogloss:2.14916\teval-mlogloss:2.36102\n",
      "[184]\ttrain-mlogloss:2.14835\teval-mlogloss:2.36093\n",
      "[185]\ttrain-mlogloss:2.14749\teval-mlogloss:2.36092\n",
      "[186]\ttrain-mlogloss:2.1466\teval-mlogloss:2.3609\n",
      "[187]\ttrain-mlogloss:2.14575\teval-mlogloss:2.36079\n",
      "[188]\ttrain-mlogloss:2.14486\teval-mlogloss:2.36072\n",
      "[189]\ttrain-mlogloss:2.14415\teval-mlogloss:2.36066\n",
      "[190]\ttrain-mlogloss:2.14333\teval-mlogloss:2.36056\n",
      "[191]\ttrain-mlogloss:2.14262\teval-mlogloss:2.3605\n",
      "[192]\ttrain-mlogloss:2.14192\teval-mlogloss:2.36043\n",
      "[193]\ttrain-mlogloss:2.14108\teval-mlogloss:2.36044\n",
      "[194]\ttrain-mlogloss:2.14032\teval-mlogloss:2.36042\n",
      "[195]\ttrain-mlogloss:2.13959\teval-mlogloss:2.36035\n",
      "[196]\ttrain-mlogloss:2.13889\teval-mlogloss:2.36031\n",
      "[197]\ttrain-mlogloss:2.13824\teval-mlogloss:2.36027\n",
      "[198]\ttrain-mlogloss:2.13745\teval-mlogloss:2.36024\n",
      "[199]\ttrain-mlogloss:2.13668\teval-mlogloss:2.36016\n",
      "[200]\ttrain-mlogloss:2.13578\teval-mlogloss:2.36006\n",
      "[201]\ttrain-mlogloss:2.13505\teval-mlogloss:2.36003\n",
      "[202]\ttrain-mlogloss:2.13431\teval-mlogloss:2.35999\n",
      "[203]\ttrain-mlogloss:2.13352\teval-mlogloss:2.35991\n",
      "[204]\ttrain-mlogloss:2.1328\teval-mlogloss:2.35986\n",
      "[205]\ttrain-mlogloss:2.13199\teval-mlogloss:2.35986\n",
      "[206]\ttrain-mlogloss:2.13123\teval-mlogloss:2.35978\n",
      "[207]\ttrain-mlogloss:2.13042\teval-mlogloss:2.35974\n",
      "[208]\ttrain-mlogloss:2.12969\teval-mlogloss:2.35969\n",
      "[209]\ttrain-mlogloss:2.12913\teval-mlogloss:2.35961\n",
      "[210]\ttrain-mlogloss:2.12829\teval-mlogloss:2.35956\n",
      "[211]\ttrain-mlogloss:2.12757\teval-mlogloss:2.3595\n",
      "[212]\ttrain-mlogloss:2.12699\teval-mlogloss:2.35946\n",
      "[213]\ttrain-mlogloss:2.12627\teval-mlogloss:2.35945\n",
      "[214]\ttrain-mlogloss:2.12551\teval-mlogloss:2.3594\n",
      "[215]\ttrain-mlogloss:2.12487\teval-mlogloss:2.35936\n",
      "[216]\ttrain-mlogloss:2.12412\teval-mlogloss:2.35933\n",
      "[217]\ttrain-mlogloss:2.12344\teval-mlogloss:2.35933\n",
      "[218]\ttrain-mlogloss:2.12272\teval-mlogloss:2.3593\n",
      "[219]\ttrain-mlogloss:2.122\teval-mlogloss:2.35926\n",
      "[220]\ttrain-mlogloss:2.12131\teval-mlogloss:2.35923\n",
      "[221]\ttrain-mlogloss:2.12048\teval-mlogloss:2.35915\n",
      "[222]\ttrain-mlogloss:2.11977\teval-mlogloss:2.35911\n",
      "[223]\ttrain-mlogloss:2.11911\teval-mlogloss:2.35907\n",
      "[224]\ttrain-mlogloss:2.11845\teval-mlogloss:2.35899\n",
      "[225]\ttrain-mlogloss:2.11786\teval-mlogloss:2.35895\n",
      "[226]\ttrain-mlogloss:2.11709\teval-mlogloss:2.3589\n",
      "[227]\ttrain-mlogloss:2.11634\teval-mlogloss:2.35887\n",
      "[228]\ttrain-mlogloss:2.11572\teval-mlogloss:2.35885\n",
      "[229]\ttrain-mlogloss:2.11507\teval-mlogloss:2.35884\n",
      "[230]\ttrain-mlogloss:2.11436\teval-mlogloss:2.35881\n",
      "[231]\ttrain-mlogloss:2.11368\teval-mlogloss:2.35876\n",
      "[232]\ttrain-mlogloss:2.11308\teval-mlogloss:2.3587\n",
      "[233]\ttrain-mlogloss:2.11248\teval-mlogloss:2.35867\n",
      "[234]\ttrain-mlogloss:2.11182\teval-mlogloss:2.35864\n",
      "[235]\ttrain-mlogloss:2.1111\teval-mlogloss:2.3586\n",
      "[236]\ttrain-mlogloss:2.11047\teval-mlogloss:2.3586\n",
      "[237]\ttrain-mlogloss:2.10967\teval-mlogloss:2.35855\n",
      "[238]\ttrain-mlogloss:2.10899\teval-mlogloss:2.35846\n",
      "[239]\ttrain-mlogloss:2.10823\teval-mlogloss:2.35845\n",
      "[240]\ttrain-mlogloss:2.10757\teval-mlogloss:2.35838\n",
      "[241]\ttrain-mlogloss:2.10684\teval-mlogloss:2.3583\n",
      "[242]\ttrain-mlogloss:2.10625\teval-mlogloss:2.3583\n",
      "[243]\ttrain-mlogloss:2.10559\teval-mlogloss:2.35826\n",
      "[244]\ttrain-mlogloss:2.10492\teval-mlogloss:2.35826\n",
      "[245]\ttrain-mlogloss:2.1042\teval-mlogloss:2.35819\n",
      "[246]\ttrain-mlogloss:2.10358\teval-mlogloss:2.35818\n",
      "[247]\ttrain-mlogloss:2.10289\teval-mlogloss:2.35817\n",
      "[248]\ttrain-mlogloss:2.10231\teval-mlogloss:2.35815\n",
      "[249]\ttrain-mlogloss:2.1016\teval-mlogloss:2.35808\n",
      "[250]\ttrain-mlogloss:2.10083\teval-mlogloss:2.35802\n",
      "[251]\ttrain-mlogloss:2.10021\teval-mlogloss:2.35798\n",
      "[252]\ttrain-mlogloss:2.09961\teval-mlogloss:2.35796\n",
      "[253]\ttrain-mlogloss:2.09897\teval-mlogloss:2.35791\n",
      "[254]\ttrain-mlogloss:2.09833\teval-mlogloss:2.3579\n",
      "[255]\ttrain-mlogloss:2.0977\teval-mlogloss:2.35786\n",
      "[256]\ttrain-mlogloss:2.09705\teval-mlogloss:2.35783\n",
      "[257]\ttrain-mlogloss:2.09648\teval-mlogloss:2.35785\n",
      "[258]\ttrain-mlogloss:2.09577\teval-mlogloss:2.35782\n",
      "[259]\ttrain-mlogloss:2.09521\teval-mlogloss:2.35779\n",
      "[260]\ttrain-mlogloss:2.09461\teval-mlogloss:2.35778\n",
      "[261]\ttrain-mlogloss:2.09394\teval-mlogloss:2.35776\n",
      "[262]\ttrain-mlogloss:2.09316\teval-mlogloss:2.3577\n",
      "[263]\ttrain-mlogloss:2.09253\teval-mlogloss:2.35763\n",
      "[264]\ttrain-mlogloss:2.0919\teval-mlogloss:2.35758\n",
      "[265]\ttrain-mlogloss:2.09128\teval-mlogloss:2.35758\n",
      "[266]\ttrain-mlogloss:2.09064\teval-mlogloss:2.35753\n",
      "[267]\ttrain-mlogloss:2.09012\teval-mlogloss:2.35747\n",
      "[268]\ttrain-mlogloss:2.08947\teval-mlogloss:2.35747\n",
      "[269]\ttrain-mlogloss:2.08885\teval-mlogloss:2.35744\n",
      "[270]\ttrain-mlogloss:2.08825\teval-mlogloss:2.3574\n",
      "[271]\ttrain-mlogloss:2.08766\teval-mlogloss:2.35735\n",
      "[272]\ttrain-mlogloss:2.08701\teval-mlogloss:2.35731\n",
      "[273]\ttrain-mlogloss:2.08643\teval-mlogloss:2.35729\n",
      "[274]\ttrain-mlogloss:2.08582\teval-mlogloss:2.35731\n",
      "[275]\ttrain-mlogloss:2.08511\teval-mlogloss:2.35731\n",
      "[276]\ttrain-mlogloss:2.08452\teval-mlogloss:2.3573\n",
      "[277]\ttrain-mlogloss:2.08387\teval-mlogloss:2.35729\n",
      "[278]\ttrain-mlogloss:2.08332\teval-mlogloss:2.35727\n",
      "[279]\ttrain-mlogloss:2.08257\teval-mlogloss:2.35718\n",
      "[280]\ttrain-mlogloss:2.08203\teval-mlogloss:2.35716\n",
      "[281]\ttrain-mlogloss:2.08144\teval-mlogloss:2.35714\n",
      "[282]\ttrain-mlogloss:2.08083\teval-mlogloss:2.35711\n",
      "[283]\ttrain-mlogloss:2.08029\teval-mlogloss:2.35708\n",
      "[284]\ttrain-mlogloss:2.0797\teval-mlogloss:2.35707\n",
      "[285]\ttrain-mlogloss:2.0792\teval-mlogloss:2.35705\n",
      "[286]\ttrain-mlogloss:2.07856\teval-mlogloss:2.35701\n",
      "[287]\ttrain-mlogloss:2.07797\teval-mlogloss:2.35703\n",
      "[288]\ttrain-mlogloss:2.07729\teval-mlogloss:2.35697\n",
      "[289]\ttrain-mlogloss:2.07667\teval-mlogloss:2.35696\n",
      "[290]\ttrain-mlogloss:2.07607\teval-mlogloss:2.35694\n",
      "[291]\ttrain-mlogloss:2.07544\teval-mlogloss:2.3569\n",
      "[292]\ttrain-mlogloss:2.0748\teval-mlogloss:2.35686\n",
      "[293]\ttrain-mlogloss:2.07434\teval-mlogloss:2.35686\n",
      "[294]\ttrain-mlogloss:2.07379\teval-mlogloss:2.35686\n",
      "[295]\ttrain-mlogloss:2.07324\teval-mlogloss:2.3568\n",
      "[296]\ttrain-mlogloss:2.07261\teval-mlogloss:2.35677\n",
      "[297]\ttrain-mlogloss:2.07202\teval-mlogloss:2.35673\n",
      "[298]\ttrain-mlogloss:2.07153\teval-mlogloss:2.3567\n",
      "[299]\ttrain-mlogloss:2.07106\teval-mlogloss:2.35667\n",
      "[300]\ttrain-mlogloss:2.07045\teval-mlogloss:2.35662\n",
      "[301]\ttrain-mlogloss:2.06982\teval-mlogloss:2.35663\n",
      "[302]\ttrain-mlogloss:2.06926\teval-mlogloss:2.35663\n",
      "[303]\ttrain-mlogloss:2.06866\teval-mlogloss:2.35659\n",
      "[304]\ttrain-mlogloss:2.06804\teval-mlogloss:2.3566\n",
      "[305]\ttrain-mlogloss:2.06738\teval-mlogloss:2.35657\n",
      "[306]\ttrain-mlogloss:2.06669\teval-mlogloss:2.35658\n",
      "[307]\ttrain-mlogloss:2.06608\teval-mlogloss:2.35655\n",
      "[308]\ttrain-mlogloss:2.06549\teval-mlogloss:2.35655\n",
      "[309]\ttrain-mlogloss:2.06487\teval-mlogloss:2.35651\n",
      "[310]\ttrain-mlogloss:2.06428\teval-mlogloss:2.35648\n",
      "[311]\ttrain-mlogloss:2.0638\teval-mlogloss:2.35647\n",
      "[312]\ttrain-mlogloss:2.06328\teval-mlogloss:2.35646\n",
      "[313]\ttrain-mlogloss:2.06265\teval-mlogloss:2.35647\n",
      "[314]\ttrain-mlogloss:2.06205\teval-mlogloss:2.35644\n",
      "[315]\ttrain-mlogloss:2.0614\teval-mlogloss:2.35642\n",
      "[316]\ttrain-mlogloss:2.06075\teval-mlogloss:2.35639\n",
      "[317]\ttrain-mlogloss:2.06016\teval-mlogloss:2.35636\n",
      "[318]\ttrain-mlogloss:2.05963\teval-mlogloss:2.35636\n",
      "[319]\ttrain-mlogloss:2.05921\teval-mlogloss:2.35636\n",
      "[320]\ttrain-mlogloss:2.05862\teval-mlogloss:2.35632\n",
      "[321]\ttrain-mlogloss:2.05793\teval-mlogloss:2.35628\n",
      "[322]\ttrain-mlogloss:2.05734\teval-mlogloss:2.35629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[323]\ttrain-mlogloss:2.05675\teval-mlogloss:2.35628\n",
      "[324]\ttrain-mlogloss:2.05626\teval-mlogloss:2.35629\n",
      "[325]\ttrain-mlogloss:2.05566\teval-mlogloss:2.35627\n",
      "[326]\ttrain-mlogloss:2.05506\teval-mlogloss:2.35628\n",
      "[327]\ttrain-mlogloss:2.0545\teval-mlogloss:2.35629\n",
      "[328]\ttrain-mlogloss:2.05392\teval-mlogloss:2.35628\n",
      "[329]\ttrain-mlogloss:2.05344\teval-mlogloss:2.35627\n",
      "[330]\ttrain-mlogloss:2.0529\teval-mlogloss:2.35629\n",
      "[331]\ttrain-mlogloss:2.0523\teval-mlogloss:2.35624\n",
      "[332]\ttrain-mlogloss:2.05178\teval-mlogloss:2.3562\n",
      "[333]\ttrain-mlogloss:2.05114\teval-mlogloss:2.35622\n",
      "[334]\ttrain-mlogloss:2.05062\teval-mlogloss:2.35618\n",
      "[335]\ttrain-mlogloss:2.05018\teval-mlogloss:2.35617\n",
      "[336]\ttrain-mlogloss:2.04963\teval-mlogloss:2.35612\n",
      "[337]\ttrain-mlogloss:2.04907\teval-mlogloss:2.35614\n",
      "[338]\ttrain-mlogloss:2.04843\teval-mlogloss:2.35612\n",
      "[339]\ttrain-mlogloss:2.04789\teval-mlogloss:2.3561\n",
      "[340]\ttrain-mlogloss:2.04738\teval-mlogloss:2.3561\n",
      "[341]\ttrain-mlogloss:2.04684\teval-mlogloss:2.35604\n",
      "[342]\ttrain-mlogloss:2.04636\teval-mlogloss:2.356\n",
      "[343]\ttrain-mlogloss:2.04601\teval-mlogloss:2.35598\n",
      "[344]\ttrain-mlogloss:2.04553\teval-mlogloss:2.35597\n",
      "[345]\ttrain-mlogloss:2.04502\teval-mlogloss:2.35594\n",
      "[346]\ttrain-mlogloss:2.04445\teval-mlogloss:2.35588\n",
      "[347]\ttrain-mlogloss:2.04381\teval-mlogloss:2.35589\n",
      "[348]\ttrain-mlogloss:2.04331\teval-mlogloss:2.35588\n",
      "[349]\ttrain-mlogloss:2.04271\teval-mlogloss:2.35587\n",
      "[350]\ttrain-mlogloss:2.04199\teval-mlogloss:2.35583\n",
      "[351]\ttrain-mlogloss:2.04149\teval-mlogloss:2.35584\n",
      "[352]\ttrain-mlogloss:2.04105\teval-mlogloss:2.35584\n",
      "[353]\ttrain-mlogloss:2.04045\teval-mlogloss:2.35582\n",
      "[354]\ttrain-mlogloss:2.03991\teval-mlogloss:2.35582\n",
      "[355]\ttrain-mlogloss:2.03937\teval-mlogloss:2.35581\n",
      "[356]\ttrain-mlogloss:2.03882\teval-mlogloss:2.35583\n",
      "[357]\ttrain-mlogloss:2.03829\teval-mlogloss:2.3558\n",
      "[358]\ttrain-mlogloss:2.03774\teval-mlogloss:2.35579\n",
      "[359]\ttrain-mlogloss:2.03716\teval-mlogloss:2.35573\n",
      "[360]\ttrain-mlogloss:2.03671\teval-mlogloss:2.3557\n",
      "[361]\ttrain-mlogloss:2.0361\teval-mlogloss:2.35567\n",
      "[362]\ttrain-mlogloss:2.0356\teval-mlogloss:2.35565\n",
      "[363]\ttrain-mlogloss:2.035\teval-mlogloss:2.35562\n",
      "[364]\ttrain-mlogloss:2.03433\teval-mlogloss:2.35558\n",
      "[365]\ttrain-mlogloss:2.03369\teval-mlogloss:2.35555\n",
      "[366]\ttrain-mlogloss:2.03315\teval-mlogloss:2.35553\n",
      "[367]\ttrain-mlogloss:2.03258\teval-mlogloss:2.35555\n",
      "[368]\ttrain-mlogloss:2.03206\teval-mlogloss:2.35555\n",
      "[369]\ttrain-mlogloss:2.03143\teval-mlogloss:2.35552\n",
      "[370]\ttrain-mlogloss:2.031\teval-mlogloss:2.35555\n",
      "[371]\ttrain-mlogloss:2.03051\teval-mlogloss:2.35555\n",
      "[372]\ttrain-mlogloss:2.03004\teval-mlogloss:2.35556\n",
      "[373]\ttrain-mlogloss:2.0295\teval-mlogloss:2.35553\n",
      "[374]\ttrain-mlogloss:2.02895\teval-mlogloss:2.35553\n",
      "[375]\ttrain-mlogloss:2.02845\teval-mlogloss:2.35554\n",
      "[376]\ttrain-mlogloss:2.02785\teval-mlogloss:2.35556\n",
      "[377]\ttrain-mlogloss:2.02724\teval-mlogloss:2.35553\n",
      "[378]\ttrain-mlogloss:2.02671\teval-mlogloss:2.35556\n",
      "[379]\ttrain-mlogloss:2.02613\teval-mlogloss:2.35556\n",
      "[380]\ttrain-mlogloss:2.02561\teval-mlogloss:2.35552\n",
      "[381]\ttrain-mlogloss:2.02512\teval-mlogloss:2.35551\n",
      "[382]\ttrain-mlogloss:2.02454\teval-mlogloss:2.35549\n",
      "[383]\ttrain-mlogloss:2.02393\teval-mlogloss:2.35549\n",
      "[384]\ttrain-mlogloss:2.02338\teval-mlogloss:2.35546\n",
      "[385]\ttrain-mlogloss:2.0228\teval-mlogloss:2.35541\n",
      "[386]\ttrain-mlogloss:2.02232\teval-mlogloss:2.35539\n",
      "[387]\ttrain-mlogloss:2.02179\teval-mlogloss:2.35539\n",
      "[388]\ttrain-mlogloss:2.02124\teval-mlogloss:2.35537\n",
      "[389]\ttrain-mlogloss:2.02068\teval-mlogloss:2.35536\n",
      "[390]\ttrain-mlogloss:2.02019\teval-mlogloss:2.35535\n",
      "[391]\ttrain-mlogloss:2.01963\teval-mlogloss:2.35533\n",
      "[392]\ttrain-mlogloss:2.01918\teval-mlogloss:2.35533\n",
      "[393]\ttrain-mlogloss:2.01885\teval-mlogloss:2.35535\n",
      "[394]\ttrain-mlogloss:2.01823\teval-mlogloss:2.35535\n",
      "[395]\ttrain-mlogloss:2.01772\teval-mlogloss:2.35531\n",
      "[396]\ttrain-mlogloss:2.01723\teval-mlogloss:2.35528\n",
      "[397]\ttrain-mlogloss:2.01673\teval-mlogloss:2.3553\n",
      "[398]\ttrain-mlogloss:2.01629\teval-mlogloss:2.35534\n",
      "[399]\ttrain-mlogloss:2.01563\teval-mlogloss:2.35532\n",
      "[400]\ttrain-mlogloss:2.01514\teval-mlogloss:2.35531\n",
      "[401]\ttrain-mlogloss:2.01451\teval-mlogloss:2.35532\n",
      "[402]\ttrain-mlogloss:2.01418\teval-mlogloss:2.35534\n",
      "[403]\ttrain-mlogloss:2.01364\teval-mlogloss:2.35533\n",
      "[404]\ttrain-mlogloss:2.01316\teval-mlogloss:2.35533\n",
      "[405]\ttrain-mlogloss:2.01259\teval-mlogloss:2.35533\n",
      "[406]\ttrain-mlogloss:2.01209\teval-mlogloss:2.35532\n",
      "[407]\ttrain-mlogloss:2.0114\teval-mlogloss:2.35531\n",
      "[408]\ttrain-mlogloss:2.01092\teval-mlogloss:2.3553\n",
      "[409]\ttrain-mlogloss:2.01041\teval-mlogloss:2.35529\n",
      "[410]\ttrain-mlogloss:2.00988\teval-mlogloss:2.35529\n",
      "[411]\ttrain-mlogloss:2.00943\teval-mlogloss:2.35532\n",
      "[412]\ttrain-mlogloss:2.00887\teval-mlogloss:2.35532\n",
      "[413]\ttrain-mlogloss:2.00836\teval-mlogloss:2.35527\n",
      "[414]\ttrain-mlogloss:2.00787\teval-mlogloss:2.35525\n",
      "[415]\ttrain-mlogloss:2.00742\teval-mlogloss:2.35527\n",
      "[416]\ttrain-mlogloss:2.00689\teval-mlogloss:2.35527\n",
      "[417]\ttrain-mlogloss:2.00639\teval-mlogloss:2.35527\n",
      "[418]\ttrain-mlogloss:2.00596\teval-mlogloss:2.35528\n",
      "[419]\ttrain-mlogloss:2.00531\teval-mlogloss:2.35527\n",
      "[420]\ttrain-mlogloss:2.00479\teval-mlogloss:2.35523\n",
      "[421]\ttrain-mlogloss:2.00431\teval-mlogloss:2.35524\n",
      "[422]\ttrain-mlogloss:2.00369\teval-mlogloss:2.35523\n",
      "[423]\ttrain-mlogloss:2.00314\teval-mlogloss:2.35522\n",
      "[424]\ttrain-mlogloss:2.00269\teval-mlogloss:2.3552\n",
      "[425]\ttrain-mlogloss:2.00216\teval-mlogloss:2.35517\n",
      "[426]\ttrain-mlogloss:2.00156\teval-mlogloss:2.35521\n",
      "[427]\ttrain-mlogloss:2.00097\teval-mlogloss:2.35518\n",
      "[428]\ttrain-mlogloss:2.00048\teval-mlogloss:2.35522\n",
      "[429]\ttrain-mlogloss:1.99987\teval-mlogloss:2.3552\n",
      "[430]\ttrain-mlogloss:1.99946\teval-mlogloss:2.35517\n",
      "[431]\ttrain-mlogloss:1.99889\teval-mlogloss:2.35516\n",
      "[432]\ttrain-mlogloss:1.99835\teval-mlogloss:2.35514\n",
      "[433]\ttrain-mlogloss:1.99793\teval-mlogloss:2.35517\n",
      "[434]\ttrain-mlogloss:1.99759\teval-mlogloss:2.35515\n",
      "[435]\ttrain-mlogloss:1.99715\teval-mlogloss:2.35518\n",
      "[436]\ttrain-mlogloss:1.99678\teval-mlogloss:2.35518\n",
      "[437]\ttrain-mlogloss:1.99623\teval-mlogloss:2.35519\n",
      "[438]\ttrain-mlogloss:1.99573\teval-mlogloss:2.35519\n",
      "[439]\ttrain-mlogloss:1.99526\teval-mlogloss:2.35518\n",
      "[440]\ttrain-mlogloss:1.99475\teval-mlogloss:2.35517\n",
      "[441]\ttrain-mlogloss:1.99425\teval-mlogloss:2.35515\n",
      "[442]\ttrain-mlogloss:1.99367\teval-mlogloss:2.35512\n",
      "[443]\ttrain-mlogloss:1.99332\teval-mlogloss:2.35512\n",
      "[444]\ttrain-mlogloss:1.99286\teval-mlogloss:2.35514\n",
      "[445]\ttrain-mlogloss:1.99239\teval-mlogloss:2.35519\n",
      "[446]\ttrain-mlogloss:1.99198\teval-mlogloss:2.35517\n",
      "[447]\ttrain-mlogloss:1.99161\teval-mlogloss:2.35519\n",
      "[448]\ttrain-mlogloss:1.99127\teval-mlogloss:2.35521\n",
      "[449]\ttrain-mlogloss:1.99086\teval-mlogloss:2.35522\n",
      "[450]\ttrain-mlogloss:1.99038\teval-mlogloss:2.35522\n",
      "[451]\ttrain-mlogloss:1.98997\teval-mlogloss:2.35523\n",
      "[452]\ttrain-mlogloss:1.98959\teval-mlogloss:2.35524\n",
      "[453]\ttrain-mlogloss:1.98907\teval-mlogloss:2.35523\n",
      "[454]\ttrain-mlogloss:1.98869\teval-mlogloss:2.35522\n",
      "[455]\ttrain-mlogloss:1.98828\teval-mlogloss:2.3552\n",
      "[456]\ttrain-mlogloss:1.98779\teval-mlogloss:2.35524\n",
      "[457]\ttrain-mlogloss:1.9872\teval-mlogloss:2.35527\n",
      "[458]\ttrain-mlogloss:1.98678\teval-mlogloss:2.35527\n",
      "[459]\ttrain-mlogloss:1.98633\teval-mlogloss:2.3553\n",
      "[460]\ttrain-mlogloss:1.98588\teval-mlogloss:2.35532\n",
      "[461]\ttrain-mlogloss:1.98546\teval-mlogloss:2.35535\n",
      "[462]\ttrain-mlogloss:1.98495\teval-mlogloss:2.3554\n",
      "Stopping. Best iteration:\n",
      "[442]\ttrain-mlogloss:1.99367\teval-mlogloss:2.35512\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_boost_round = 500\n",
    "early_stopping_rounds = 20\n",
    "\n",
    "watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "gbm = xgb.train(params, dtrain, num_boost_round, evals=watchlist, early_stopping_rounds=early_stopping_rounds, verbose_eval=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "from operator import itemgetter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = gbm.predict(xgb.DMatrix(X_test), ntree_limit=gbm.best_iteration)\n",
    "score = log_loss(y_test.tolist(), check)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3551548588004345"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.30082253, 0.12324033, 0.0057063 , ..., 0.05311341, 0.00342177,\n",
       "        0.03004985],\n",
       "       [0.12575394, 0.09502217, 0.05278345, ..., 0.07438413, 0.0597569 ,\n",
       "        0.05409901],\n",
       "       [0.19870761, 0.14577486, 0.02650973, ..., 0.0516676 , 0.030261  ,\n",
       "        0.05127193],\n",
       "       ...,\n",
       "       [0.14253932, 0.10449717, 0.06498302, ..., 0.06948732, 0.02158727,\n",
       "        0.09496325],\n",
       "       [0.12070145, 0.10254435, 0.07054647, ..., 0.05689305, 0.05710029,\n",
       "        0.05750619],\n",
       "       [0.34038422, 0.10234085, 0.01483704, ..., 0.01484205, 0.00532037,\n",
       "        0.01766218]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_map(features):\n",
    "    outfile = open('xgb.fmap', 'w')\n",
    "    for i, feat in enumerate(features):\n",
    "        outfile.write('{0}\\t{1}\\tq\\n'.format(i, feat))\n",
    "    outfile.close()\n",
    "\n",
    "\n",
    "def get_importance(gbm, features):\n",
    "    create_feature_map(features)\n",
    "    importance = gbm.get_fscore(fmap='xgb.fmap')\n",
    "    importance = sorted(importance.items(), key=itemgetter(1), reverse=True)\n",
    "    return importance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = get_importance(gbm, magyarazo_valtozok)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('device_model', 29781),\n",
       " ('events_per_day', 17587),\n",
       " ('phone_brand_eng', 15922),\n",
       " ('label_i_714', 8796),\n",
       " ('label_i_128', 8354),\n",
       " ('label_i_179', 8041),\n",
       " ('label_22222', 7945),\n",
       " ('label_i_721', 7774),\n",
       " ('label_i_22222', 7684),\n",
       " ('weekday_daytime', 7414),\n",
       " ('label_i_306', 7197),\n",
       " ('label_i_710', 6963),\n",
       " ('label_i_303', 6421),\n",
       " ('label_i_251', 6352),\n",
       " ('label_i_713', 6323),\n",
       " ('label_i_549', 6223),\n",
       " ('weekday_night', 6059),\n",
       " ('label_128', 5965),\n",
       " ('weekday_evening', 5938),\n",
       " ('events_num', 5933),\n",
       " ('label_i_172', 5928),\n",
       " ('label_548', 5881),\n",
       " ('label_i_786', 5870),\n",
       " ('label_713', 5864),\n",
       " ('label_721', 5843),\n",
       " ('label_306', 5794),\n",
       " ('label_i_302', 5778),\n",
       " ('weekend_daytime', 5752),\n",
       " ('weekday_morning', 5615),\n",
       " ('label_179', 5493),\n",
       " ('label_302', 5482),\n",
       " ('label_714', 5481),\n",
       " ('label_i_548', 5449),\n",
       " ('label_549', 5447),\n",
       " ('label_i_704', 5299),\n",
       " ('label_704', 5187),\n",
       " ('label_i_252', 5158),\n",
       " ('label_303', 5100),\n",
       " ('label_i_405', 4895),\n",
       " ('label_i_775', 4770),\n",
       " ('label_i_783', 4703),\n",
       " ('label_252', 4702),\n",
       " ('label_i_263', 4675),\n",
       " ('label_710', 4585),\n",
       " ('label_263', 4569),\n",
       " ('label_i_1007', 4511),\n",
       " ('label_172', 4414),\n",
       " ('label_i_959', 4351),\n",
       " ('label_i_730', 4309),\n",
       " ('weekend_night', 4292),\n",
       " ('weekend_morning', 4050),\n",
       " ('label_251', 4014),\n",
       " ('weekend_evening', 3991),\n",
       " ('label_786', 3859),\n",
       " ('label_i_756', 3830),\n",
       " ('label_405', 3660),\n",
       " ('label_i_782', 3424),\n",
       " ('label_1007', 3221),\n",
       " ('label_i_777', 3097),\n",
       " ('label_775', 3038),\n",
       " ('label_959', 2952),\n",
       " ('label_783', 2927),\n",
       " ('label_i_779', 2746),\n",
       " ('label_730', 2502),\n",
       " ('label_756', 2485),\n",
       " ('label_i_787', 2429),\n",
       " ('label_i_757', 2367),\n",
       " ('label_782', 2296),\n",
       " ('label_777', 1603),\n",
       " ('label_779', 1567),\n",
       " ('label_787', 1332),\n",
       " ('label_i_960', 982),\n",
       " ('label_757', 902),\n",
       " ('label_960', 752)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "estimator should be an estimator implementing 'fit' method, <xgboost.core.Booster object at 0x7f0d1e6cb750> was passed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-723d9fcdd438>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgbm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'f1_weighted'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \"\"\"\n\u001b[1;32m    383\u001b[0m     \u001b[0;31m# To ensure multimetric format is not supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m     \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m     cv_results = cross_validate(estimator=estimator, X=X, y=y, groups=groups,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/scorer.py\u001b[0m in \u001b[0;36mcheck_scoring\u001b[0;34m(estimator, scoring, allow_none)\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         raise TypeError(\"estimator should be an estimator implementing \"\n\u001b[0;32m--> 270\u001b[0;31m                         \"'fit' method, %r was passed\" % estimator)\n\u001b[0m\u001b[1;32m    271\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mget_scorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: estimator should be an estimator implementing 'fit' method, <xgboost.core.Booster object at 0x7f0d1e6cb750> was passed"
     ]
    }
   ],
   "source": [
    "cross_val_score(estimator=gbm,X=X_test,y=y_test,scoring='f1_weighted',cv=5)\n",
    "print (classification_report(y_true=Y_test,y_pred=gb.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
