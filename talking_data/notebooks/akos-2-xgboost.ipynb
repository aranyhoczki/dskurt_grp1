{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # pandas\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  XGBoost\n",
    "https://www.kaggle.com/tilii7/xgboost-simple-starter-more-features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akos/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#Importing Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.externals import joblib\n",
    "from sklearn import metrics\n",
    "import xgboost as xgb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../datasets/train1.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>device_id</th>\n",
       "      <th>events_num</th>\n",
       "      <th>min_timestamp</th>\n",
       "      <th>max_timestamp</th>\n",
       "      <th>events_per_day</th>\n",
       "      <th>label_548</th>\n",
       "      <th>label_i_548</th>\n",
       "      <th>label_704</th>\n",
       "      <th>label_i_704</th>\n",
       "      <th>...</th>\n",
       "      <th>label_787</th>\n",
       "      <th>label_i_787</th>\n",
       "      <th>label_22222</th>\n",
       "      <th>label_i_22222</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>group</th>\n",
       "      <th>phone_brand</th>\n",
       "      <th>device_model</th>\n",
       "      <th>phone_brand_eng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-8260683887967679142</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-05-01 14:23:37</td>\n",
       "      <td>2016-05-01 14:23:37</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>102</td>\n",
       "      <td>M</td>\n",
       "      <td>35</td>\n",
       "      <td>M32-38</td>\n",
       "      <td>小米</td>\n",
       "      <td>MI 2</td>\n",
       "      <td>Xiaomi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7477216237379271436</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-05-04 14:08:17</td>\n",
       "      <td>2016-05-06 18:51:15</td>\n",
       "      <td>0.065502</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>25</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>78</td>\n",
       "      <td>F</td>\n",
       "      <td>37</td>\n",
       "      <td>F33-42</td>\n",
       "      <td>华为</td>\n",
       "      <td>荣耀6 plus</td>\n",
       "      <td>Huawei</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>6352067998666467520</td>\n",
       "      <td>11</td>\n",
       "      <td>2016-05-03 22:14:30</td>\n",
       "      <td>2016-05-05 17:27:58</td>\n",
       "      <td>0.072820</td>\n",
       "      <td>70</td>\n",
       "      <td>34</td>\n",
       "      <td>57</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>211</td>\n",
       "      <td>103</td>\n",
       "      <td>M</td>\n",
       "      <td>32</td>\n",
       "      <td>M32-38</td>\n",
       "      <td>华为</td>\n",
       "      <td>荣耀畅玩4X</td>\n",
       "      <td>Huawei</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1508636020748379883</td>\n",
       "      <td>5</td>\n",
       "      <td>2016-05-01 12:41:38</td>\n",
       "      <td>2016-05-05 12:34:15</td>\n",
       "      <td>0.198975</td>\n",
       "      <td>50</td>\n",
       "      <td>39</td>\n",
       "      <td>38</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>69</td>\n",
       "      <td>80</td>\n",
       "      <td>F</td>\n",
       "      <td>28</td>\n",
       "      <td>F27-28</td>\n",
       "      <td>华为</td>\n",
       "      <td>荣耀畅玩4X</td>\n",
       "      <td>Huawei</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-6876541075223249434</td>\n",
       "      <td>6</td>\n",
       "      <td>2016-05-01 02:51:41</td>\n",
       "      <td>2016-05-06 16:30:01</td>\n",
       "      <td>0.094715</td>\n",
       "      <td>63</td>\n",
       "      <td>187</td>\n",
       "      <td>46</td>\n",
       "      <td>162</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>126</td>\n",
       "      <td>520</td>\n",
       "      <td>M</td>\n",
       "      <td>75</td>\n",
       "      <td>M39+</td>\n",
       "      <td>魅族</td>\n",
       "      <td>魅蓝NOTE</td>\n",
       "      <td>Meizu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0            device_id  events_num        min_timestamp  \\\n",
       "0           0 -8260683887967679142           1  2016-05-01 14:23:37   \n",
       "1           1  7477216237379271436           3  2016-05-04 14:08:17   \n",
       "2           2  6352067998666467520          11  2016-05-03 22:14:30   \n",
       "3           3  1508636020748379883           5  2016-05-01 12:41:38   \n",
       "4           4 -6876541075223249434           6  2016-05-01 02:51:41   \n",
       "\n",
       "         max_timestamp  events_per_day  label_548  label_i_548  label_704  \\\n",
       "0  2016-05-01 14:23:37        0.000000          5           30          3   \n",
       "1  2016-05-06 18:51:15        0.065502         31           29         25   \n",
       "2  2016-05-05 17:27:58        0.072820         70           34         57   \n",
       "3  2016-05-05 12:34:15        0.198975         50           39         38   \n",
       "4  2016-05-06 16:30:01        0.094715         63          187         46   \n",
       "\n",
       "   label_i_704       ...         label_787  label_i_787  label_22222  \\\n",
       "0           24       ...                 0            0            4   \n",
       "1           17       ...                 3            0           27   \n",
       "2           19       ...                11            0          211   \n",
       "3           36       ...                 2            3           69   \n",
       "4          162       ...                 0            0          126   \n",
       "\n",
       "   label_i_22222  gender  age   group  phone_brand  device_model  \\\n",
       "0            102       M   35  M32-38           小米          MI 2   \n",
       "1             78       F   37  F33-42           华为      荣耀6 plus   \n",
       "2            103       M   32  M32-38           华为        荣耀畅玩4X   \n",
       "3             80       F   28  F27-28           华为        荣耀畅玩4X   \n",
       "4            520       M   75    M39+           魅族        魅蓝NOTE   \n",
       "\n",
       "   phone_brand_eng  \n",
       "0           Xiaomi  \n",
       "1           Huawei  \n",
       "2           Huawei  \n",
       "3           Huawei  \n",
       "4            Meizu  \n",
       "\n",
       "[5 rows x 74 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   num_boost_round = 500\n",
    "    early_stopping_rounds = 20\n",
    "    test_size = 0.2\n",
    "\n",
    "    X_train, X_valid = train_test_split(train, test_size=test_size, random_state=random_state)\n",
    "    print('Length train:', len(X_train.index))\n",
    "    print('Length valid:', len(X_valid.index))\n",
    "    y_train = X_train[target]\n",
    "    y_valid = X_valid[target]\n",
    "    dtrain = xgb.DMatrix(X_train[features], y_train)\n",
    "    dvalid = xgb.DMatrix(X_valid[features], y_valid)\n",
    "\n",
    "    watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "    gbm = xgb.train(params, dtrain, num_boost_round, evals=watchlist, early_stopping_rounds=early_stopping_rounds, verbose_eval=True)\n",
    "\n",
    "    print(\"Validating...\")\n",
    "    check = gbm.predict(xgb.DMatrix(X_valid[features]), ntree_limit=gbm.best_iteration)\n",
    "    score = log_loss(y_valid.tolist(), check)\n",
    "\n",
    "    imp = get_importance(gbm, features)\n",
    "    print('Importance array: ', imp)\n",
    "\n",
    "    print(\"Predict test set...\")\n",
    "    test_prediction = gbm.predict(xgb.DMatrix(test[features]), ntree_limit=gbm.best_iteration)\n",
    "\n",
    "    print('Training time: {} minutes'.format(round((time.time() - start_time)/60, 2)))\n",
    "    return test_prediction.tolist(), score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor = pd.factorize(df_train['phone_brand_eng'])\n",
    "df_train.phone_brand_eng = factor[0]\n",
    "definitions_phone_brand_eng = factor[1]\n",
    "factor = pd.factorize(df_train['device_model'])\n",
    "df_train.device_model = factor[0]\n",
    "definitions_device_model = factor[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor = pd.factorize(df_train['group'])\n",
    "df_train.group = factor[0]\n",
    "definitions = factor[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "magyarazo_valtozok = []\n",
    "for m in df_train.columns:\n",
    "    if m not in ['Unnamed: 0', 'device_id', 'min_timestamp', 'max_timestamp','gender', 'age', 'group', 'phone_brand' ]:\n",
    "        magyarazo_valtozok += [m]\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_train[magyarazo_valtozok], df_train['group'], test_size=0.2,random_state=109) # 90% training and 10% test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akos/anaconda3/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(X_train, y_train)\n",
    "dvalid = xgb.DMatrix(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>device_id</th>\n",
       "      <th>events_num</th>\n",
       "      <th>min_timestamp</th>\n",
       "      <th>max_timestamp</th>\n",
       "      <th>events_per_day</th>\n",
       "      <th>label_548</th>\n",
       "      <th>label_i_548</th>\n",
       "      <th>label_704</th>\n",
       "      <th>label_i_704</th>\n",
       "      <th>...</th>\n",
       "      <th>label_787</th>\n",
       "      <th>label_i_787</th>\n",
       "      <th>label_22222</th>\n",
       "      <th>label_i_22222</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>group</th>\n",
       "      <th>phone_brand</th>\n",
       "      <th>device_model</th>\n",
       "      <th>phone_brand_eng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-8260683887967679142</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-05-01 14:23:37</td>\n",
       "      <td>2016-05-01 14:23:37</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>102</td>\n",
       "      <td>M</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>小米</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7477216237379271436</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-05-04 14:08:17</td>\n",
       "      <td>2016-05-06 18:51:15</td>\n",
       "      <td>0.065502</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>25</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>78</td>\n",
       "      <td>F</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>华为</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>6352067998666467520</td>\n",
       "      <td>11</td>\n",
       "      <td>2016-05-03 22:14:30</td>\n",
       "      <td>2016-05-05 17:27:58</td>\n",
       "      <td>0.072820</td>\n",
       "      <td>70</td>\n",
       "      <td>34</td>\n",
       "      <td>57</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>211</td>\n",
       "      <td>103</td>\n",
       "      <td>M</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>华为</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1508636020748379883</td>\n",
       "      <td>5</td>\n",
       "      <td>2016-05-01 12:41:38</td>\n",
       "      <td>2016-05-05 12:34:15</td>\n",
       "      <td>0.198975</td>\n",
       "      <td>50</td>\n",
       "      <td>39</td>\n",
       "      <td>38</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>69</td>\n",
       "      <td>80</td>\n",
       "      <td>F</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>华为</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-6876541075223249434</td>\n",
       "      <td>6</td>\n",
       "      <td>2016-05-01 02:51:41</td>\n",
       "      <td>2016-05-06 16:30:01</td>\n",
       "      <td>0.094715</td>\n",
       "      <td>63</td>\n",
       "      <td>187</td>\n",
       "      <td>46</td>\n",
       "      <td>162</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>126</td>\n",
       "      <td>520</td>\n",
       "      <td>M</td>\n",
       "      <td>75</td>\n",
       "      <td>3</td>\n",
       "      <td>魅族</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0            device_id  events_num        min_timestamp  \\\n",
       "0           0 -8260683887967679142           1  2016-05-01 14:23:37   \n",
       "1           1  7477216237379271436           3  2016-05-04 14:08:17   \n",
       "2           2  6352067998666467520          11  2016-05-03 22:14:30   \n",
       "3           3  1508636020748379883           5  2016-05-01 12:41:38   \n",
       "4           4 -6876541075223249434           6  2016-05-01 02:51:41   \n",
       "\n",
       "         max_timestamp  events_per_day  label_548  label_i_548  label_704  \\\n",
       "0  2016-05-01 14:23:37        0.000000          5           30          3   \n",
       "1  2016-05-06 18:51:15        0.065502         31           29         25   \n",
       "2  2016-05-05 17:27:58        0.072820         70           34         57   \n",
       "3  2016-05-05 12:34:15        0.198975         50           39         38   \n",
       "4  2016-05-06 16:30:01        0.094715         63          187         46   \n",
       "\n",
       "   label_i_704       ...         label_787  label_i_787  label_22222  \\\n",
       "0           24       ...                 0            0            4   \n",
       "1           17       ...                 3            0           27   \n",
       "2           19       ...                11            0          211   \n",
       "3           36       ...                 2            3           69   \n",
       "4          162       ...                 0            0          126   \n",
       "\n",
       "   label_i_22222  gender  age  group  phone_brand  device_model  \\\n",
       "0            102       M   35      0           小米             0   \n",
       "1             78       F   37      1           华为             1   \n",
       "2            103       M   32      0           华为             2   \n",
       "3             80       F   28      2           华为             2   \n",
       "4            520       M   75      3           魅族             3   \n",
       "\n",
       "   phone_brand_eng  \n",
       "0                0  \n",
       "1                1  \n",
       "2                1  \n",
       "3                1  \n",
       "4                2  \n",
       "\n",
       "[5 rows x 74 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb parameterek ... nem tudom, hogy mi hogy számít...\n",
    "\n",
    "eta = 0.025\n",
    "max_depth = 7\n",
    "subsample = 0.75\n",
    "colsample_bytree = 0.75\n",
    "random_state=123\n",
    "params = {\n",
    "        \"objective\": \"multi:softprob\",\n",
    "        \"num_class\": 12,\n",
    "        \"booster\" : \"gbtree\",\n",
    "        \"eval_metric\": \"mlogloss\",\n",
    "        \"eta\": eta,\n",
    "        \"max_depth\": max_depth,\n",
    "        \"subsample\": subsample,\n",
    "        \"colsample_bytree\": colsample_bytree,\n",
    "        \"silent\": 1,\n",
    "        \"seed\": random_state,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:2.47313\teval-mlogloss:2.4798\n",
      "Multiple eval metrics have been passed: 'eval-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until eval-mlogloss hasn't improved in 20 rounds.\n",
      "[1]\ttrain-mlogloss:2.46153\teval-mlogloss:2.47475\n",
      "[2]\ttrain-mlogloss:2.45071\teval-mlogloss:2.4696\n",
      "[3]\ttrain-mlogloss:2.43941\teval-mlogloss:2.46444\n",
      "[4]\ttrain-mlogloss:2.42866\teval-mlogloss:2.45931\n",
      "[5]\ttrain-mlogloss:2.41809\teval-mlogloss:2.4545\n",
      "[6]\ttrain-mlogloss:2.4079\teval-mlogloss:2.45\n",
      "[7]\ttrain-mlogloss:2.39822\teval-mlogloss:2.44578\n",
      "[8]\ttrain-mlogloss:2.38835\teval-mlogloss:2.44154\n",
      "[9]\ttrain-mlogloss:2.3786\teval-mlogloss:2.43752\n",
      "[10]\ttrain-mlogloss:2.36919\teval-mlogloss:2.43365\n",
      "[11]\ttrain-mlogloss:2.35975\teval-mlogloss:2.42994\n",
      "[12]\ttrain-mlogloss:2.35064\teval-mlogloss:2.42614\n",
      "[13]\ttrain-mlogloss:2.34164\teval-mlogloss:2.42259\n",
      "[14]\ttrain-mlogloss:2.33275\teval-mlogloss:2.41898\n",
      "[15]\ttrain-mlogloss:2.32385\teval-mlogloss:2.41543\n",
      "[16]\ttrain-mlogloss:2.31495\teval-mlogloss:2.41188\n",
      "[17]\ttrain-mlogloss:2.30646\teval-mlogloss:2.4087\n",
      "[18]\ttrain-mlogloss:2.29818\teval-mlogloss:2.40584\n",
      "[19]\ttrain-mlogloss:2.28962\teval-mlogloss:2.4027\n",
      "[20]\ttrain-mlogloss:2.28139\teval-mlogloss:2.39949\n",
      "[21]\ttrain-mlogloss:2.27347\teval-mlogloss:2.39657\n",
      "[22]\ttrain-mlogloss:2.26553\teval-mlogloss:2.394\n",
      "[23]\ttrain-mlogloss:2.25779\teval-mlogloss:2.39088\n",
      "[24]\ttrain-mlogloss:2.25004\teval-mlogloss:2.38831\n",
      "[25]\ttrain-mlogloss:2.24246\teval-mlogloss:2.38574\n",
      "[26]\ttrain-mlogloss:2.23495\teval-mlogloss:2.38313\n",
      "[27]\ttrain-mlogloss:2.2277\teval-mlogloss:2.38062\n",
      "[28]\ttrain-mlogloss:2.22046\teval-mlogloss:2.37808\n",
      "[29]\ttrain-mlogloss:2.21315\teval-mlogloss:2.37594\n",
      "[30]\ttrain-mlogloss:2.20601\teval-mlogloss:2.37365\n",
      "[31]\ttrain-mlogloss:2.19893\teval-mlogloss:2.3713\n",
      "[32]\ttrain-mlogloss:2.19247\teval-mlogloss:2.36918\n",
      "[33]\ttrain-mlogloss:2.18557\teval-mlogloss:2.36708\n",
      "[34]\ttrain-mlogloss:2.17856\teval-mlogloss:2.3646\n",
      "[35]\ttrain-mlogloss:2.17194\teval-mlogloss:2.36242\n",
      "[36]\ttrain-mlogloss:2.1654\teval-mlogloss:2.36035\n",
      "[37]\ttrain-mlogloss:2.15889\teval-mlogloss:2.35835\n",
      "[38]\ttrain-mlogloss:2.15202\teval-mlogloss:2.35647\n",
      "[39]\ttrain-mlogloss:2.14566\teval-mlogloss:2.35469\n",
      "[40]\ttrain-mlogloss:2.13926\teval-mlogloss:2.35293\n",
      "[41]\ttrain-mlogloss:2.13282\teval-mlogloss:2.35104\n",
      "[42]\ttrain-mlogloss:2.12648\teval-mlogloss:2.34912\n",
      "[43]\ttrain-mlogloss:2.12036\teval-mlogloss:2.34752\n",
      "[44]\ttrain-mlogloss:2.11429\teval-mlogloss:2.34567\n",
      "[45]\ttrain-mlogloss:2.10833\teval-mlogloss:2.3441\n",
      "[46]\ttrain-mlogloss:2.1023\teval-mlogloss:2.34245\n",
      "[47]\ttrain-mlogloss:2.09642\teval-mlogloss:2.34097\n",
      "[48]\ttrain-mlogloss:2.09045\teval-mlogloss:2.33956\n",
      "[49]\ttrain-mlogloss:2.08444\teval-mlogloss:2.33814\n",
      "[50]\ttrain-mlogloss:2.07867\teval-mlogloss:2.33662\n",
      "[51]\ttrain-mlogloss:2.07322\teval-mlogloss:2.33517\n",
      "[52]\ttrain-mlogloss:2.06742\teval-mlogloss:2.33373\n",
      "[53]\ttrain-mlogloss:2.06201\teval-mlogloss:2.33245\n",
      "[54]\ttrain-mlogloss:2.05632\teval-mlogloss:2.33112\n",
      "[55]\ttrain-mlogloss:2.05103\teval-mlogloss:2.32989\n",
      "[56]\ttrain-mlogloss:2.04533\teval-mlogloss:2.32846\n",
      "[57]\ttrain-mlogloss:2.03982\teval-mlogloss:2.32728\n",
      "[58]\ttrain-mlogloss:2.03456\teval-mlogloss:2.326\n",
      "[59]\ttrain-mlogloss:2.02949\teval-mlogloss:2.32469\n",
      "[60]\ttrain-mlogloss:2.02443\teval-mlogloss:2.32367\n",
      "[61]\ttrain-mlogloss:2.01909\teval-mlogloss:2.32254\n",
      "[62]\ttrain-mlogloss:2.01378\teval-mlogloss:2.32143\n",
      "[63]\ttrain-mlogloss:2.00874\teval-mlogloss:2.32021\n",
      "[64]\ttrain-mlogloss:2.00381\teval-mlogloss:2.31925\n",
      "[65]\ttrain-mlogloss:1.99893\teval-mlogloss:2.31816\n",
      "[66]\ttrain-mlogloss:1.99375\teval-mlogloss:2.31705\n",
      "[67]\ttrain-mlogloss:1.98877\teval-mlogloss:2.31603\n",
      "[68]\ttrain-mlogloss:1.98399\teval-mlogloss:2.31504\n",
      "[69]\ttrain-mlogloss:1.97902\teval-mlogloss:2.31413\n",
      "[70]\ttrain-mlogloss:1.97419\teval-mlogloss:2.31313\n",
      "[71]\ttrain-mlogloss:1.96962\teval-mlogloss:2.31209\n",
      "[72]\ttrain-mlogloss:1.96467\teval-mlogloss:2.31108\n",
      "[73]\ttrain-mlogloss:1.96002\teval-mlogloss:2.3102\n",
      "[74]\ttrain-mlogloss:1.95549\teval-mlogloss:2.30925\n",
      "[75]\ttrain-mlogloss:1.95113\teval-mlogloss:2.30828\n",
      "[76]\ttrain-mlogloss:1.94657\teval-mlogloss:2.30732\n",
      "[77]\ttrain-mlogloss:1.94197\teval-mlogloss:2.30635\n",
      "[78]\ttrain-mlogloss:1.93749\teval-mlogloss:2.30557\n",
      "[79]\ttrain-mlogloss:1.93318\teval-mlogloss:2.30507\n",
      "[80]\ttrain-mlogloss:1.92848\teval-mlogloss:2.30421\n",
      "[81]\ttrain-mlogloss:1.92408\teval-mlogloss:2.30333\n",
      "[82]\ttrain-mlogloss:1.91971\teval-mlogloss:2.30244\n",
      "[83]\ttrain-mlogloss:1.91554\teval-mlogloss:2.30167\n",
      "[84]\ttrain-mlogloss:1.91095\teval-mlogloss:2.30088\n",
      "[85]\ttrain-mlogloss:1.90681\teval-mlogloss:2.30021\n",
      "[86]\ttrain-mlogloss:1.90265\teval-mlogloss:2.29956\n",
      "[87]\ttrain-mlogloss:1.89828\teval-mlogloss:2.29886\n",
      "[88]\ttrain-mlogloss:1.89383\teval-mlogloss:2.29813\n",
      "[89]\ttrain-mlogloss:1.88971\teval-mlogloss:2.29757\n",
      "[90]\ttrain-mlogloss:1.88563\teval-mlogloss:2.29695\n",
      "[91]\ttrain-mlogloss:1.88132\teval-mlogloss:2.29611\n",
      "[92]\ttrain-mlogloss:1.87731\teval-mlogloss:2.29563\n",
      "[93]\ttrain-mlogloss:1.87333\teval-mlogloss:2.29497\n",
      "[94]\ttrain-mlogloss:1.86918\teval-mlogloss:2.29422\n",
      "[95]\ttrain-mlogloss:1.86509\teval-mlogloss:2.29368\n",
      "[96]\ttrain-mlogloss:1.86106\teval-mlogloss:2.29317\n",
      "[97]\ttrain-mlogloss:1.85687\teval-mlogloss:2.29235\n",
      "[98]\ttrain-mlogloss:1.85302\teval-mlogloss:2.2918\n",
      "[99]\ttrain-mlogloss:1.84915\teval-mlogloss:2.29128\n",
      "[100]\ttrain-mlogloss:1.84517\teval-mlogloss:2.29072\n",
      "[101]\ttrain-mlogloss:1.84126\teval-mlogloss:2.2902\n",
      "[102]\ttrain-mlogloss:1.83717\teval-mlogloss:2.28955\n",
      "[103]\ttrain-mlogloss:1.83336\teval-mlogloss:2.2892\n",
      "[104]\ttrain-mlogloss:1.8295\teval-mlogloss:2.28883\n",
      "[105]\ttrain-mlogloss:1.82559\teval-mlogloss:2.28845\n",
      "[106]\ttrain-mlogloss:1.82176\teval-mlogloss:2.28798\n",
      "[107]\ttrain-mlogloss:1.81785\teval-mlogloss:2.28749\n",
      "[108]\ttrain-mlogloss:1.81412\teval-mlogloss:2.28715\n",
      "[109]\ttrain-mlogloss:1.81063\teval-mlogloss:2.28674\n",
      "[110]\ttrain-mlogloss:1.80693\teval-mlogloss:2.28623\n",
      "[111]\ttrain-mlogloss:1.80358\teval-mlogloss:2.286\n",
      "[112]\ttrain-mlogloss:1.79971\teval-mlogloss:2.28579\n",
      "[113]\ttrain-mlogloss:1.79604\teval-mlogloss:2.28541\n",
      "[114]\ttrain-mlogloss:1.79261\teval-mlogloss:2.2849\n",
      "[115]\ttrain-mlogloss:1.78912\teval-mlogloss:2.28461\n",
      "[116]\ttrain-mlogloss:1.7854\teval-mlogloss:2.28421\n",
      "[117]\ttrain-mlogloss:1.78193\teval-mlogloss:2.28366\n",
      "[118]\ttrain-mlogloss:1.7783\teval-mlogloss:2.28332\n",
      "[119]\ttrain-mlogloss:1.77464\teval-mlogloss:2.28278\n",
      "[120]\ttrain-mlogloss:1.77186\teval-mlogloss:2.28244\n",
      "[121]\ttrain-mlogloss:1.76842\teval-mlogloss:2.28202\n",
      "[122]\ttrain-mlogloss:1.76486\teval-mlogloss:2.28154\n",
      "[123]\ttrain-mlogloss:1.76144\teval-mlogloss:2.2811\n",
      "[124]\ttrain-mlogloss:1.7579\teval-mlogloss:2.28081\n",
      "[125]\ttrain-mlogloss:1.75456\teval-mlogloss:2.28051\n",
      "[126]\ttrain-mlogloss:1.75125\teval-mlogloss:2.28033\n",
      "[127]\ttrain-mlogloss:1.74807\teval-mlogloss:2.27991\n",
      "[128]\ttrain-mlogloss:1.74479\teval-mlogloss:2.27953\n",
      "[129]\ttrain-mlogloss:1.74151\teval-mlogloss:2.27929\n",
      "[130]\ttrain-mlogloss:1.73812\teval-mlogloss:2.27894\n",
      "[131]\ttrain-mlogloss:1.73518\teval-mlogloss:2.27859\n",
      "[132]\ttrain-mlogloss:1.73221\teval-mlogloss:2.27825\n",
      "[133]\ttrain-mlogloss:1.72886\teval-mlogloss:2.27802\n",
      "[134]\ttrain-mlogloss:1.72598\teval-mlogloss:2.27782\n",
      "[135]\ttrain-mlogloss:1.72293\teval-mlogloss:2.27755\n",
      "[136]\ttrain-mlogloss:1.71949\teval-mlogloss:2.27725\n",
      "[137]\ttrain-mlogloss:1.71625\teval-mlogloss:2.27696\n",
      "[138]\ttrain-mlogloss:1.71321\teval-mlogloss:2.27671\n",
      "[139]\ttrain-mlogloss:1.7099\teval-mlogloss:2.27645\n",
      "[140]\ttrain-mlogloss:1.70678\teval-mlogloss:2.27605\n",
      "[141]\ttrain-mlogloss:1.70377\teval-mlogloss:2.2759\n",
      "[142]\ttrain-mlogloss:1.7003\teval-mlogloss:2.27561\n",
      "[143]\ttrain-mlogloss:1.69706\teval-mlogloss:2.27537\n",
      "[144]\ttrain-mlogloss:1.69397\teval-mlogloss:2.27515\n",
      "[145]\ttrain-mlogloss:1.6903\teval-mlogloss:2.27491\n",
      "[146]\ttrain-mlogloss:1.6871\teval-mlogloss:2.2748\n",
      "[147]\ttrain-mlogloss:1.68401\teval-mlogloss:2.2748\n",
      "[148]\ttrain-mlogloss:1.68096\teval-mlogloss:2.27466\n",
      "[149]\ttrain-mlogloss:1.67796\teval-mlogloss:2.27448\n",
      "[150]\ttrain-mlogloss:1.67449\teval-mlogloss:2.2742\n",
      "[151]\ttrain-mlogloss:1.67165\teval-mlogloss:2.27396\n",
      "[152]\ttrain-mlogloss:1.6686\teval-mlogloss:2.27378\n",
      "[153]\ttrain-mlogloss:1.66542\teval-mlogloss:2.27349\n",
      "[154]\ttrain-mlogloss:1.66261\teval-mlogloss:2.27332\n",
      "[155]\ttrain-mlogloss:1.65986\teval-mlogloss:2.27313\n",
      "[156]\ttrain-mlogloss:1.65714\teval-mlogloss:2.27278\n",
      "[157]\ttrain-mlogloss:1.65399\teval-mlogloss:2.27272\n",
      "[158]\ttrain-mlogloss:1.65065\teval-mlogloss:2.27246\n",
      "[159]\ttrain-mlogloss:1.64775\teval-mlogloss:2.27231\n",
      "[160]\ttrain-mlogloss:1.64449\teval-mlogloss:2.2721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[161]\ttrain-mlogloss:1.64135\teval-mlogloss:2.27185\n",
      "[162]\ttrain-mlogloss:1.63849\teval-mlogloss:2.27188\n",
      "[163]\ttrain-mlogloss:1.63561\teval-mlogloss:2.2716\n",
      "[164]\ttrain-mlogloss:1.63287\teval-mlogloss:2.27141\n",
      "[165]\ttrain-mlogloss:1.6301\teval-mlogloss:2.27134\n",
      "[166]\ttrain-mlogloss:1.62735\teval-mlogloss:2.27098\n",
      "[167]\ttrain-mlogloss:1.62456\teval-mlogloss:2.27097\n",
      "[168]\ttrain-mlogloss:1.62183\teval-mlogloss:2.27074\n",
      "[169]\ttrain-mlogloss:1.61916\teval-mlogloss:2.27058\n",
      "[170]\ttrain-mlogloss:1.61654\teval-mlogloss:2.27049\n",
      "[171]\ttrain-mlogloss:1.61369\teval-mlogloss:2.27035\n",
      "[172]\ttrain-mlogloss:1.61072\teval-mlogloss:2.27027\n",
      "[173]\ttrain-mlogloss:1.60772\teval-mlogloss:2.27028\n",
      "[174]\ttrain-mlogloss:1.60497\teval-mlogloss:2.27001\n",
      "[175]\ttrain-mlogloss:1.6025\teval-mlogloss:2.26995\n",
      "[176]\ttrain-mlogloss:1.59936\teval-mlogloss:2.2696\n",
      "[177]\ttrain-mlogloss:1.59671\teval-mlogloss:2.26938\n",
      "[178]\ttrain-mlogloss:1.59393\teval-mlogloss:2.26923\n",
      "[179]\ttrain-mlogloss:1.59133\teval-mlogloss:2.26899\n",
      "[180]\ttrain-mlogloss:1.58859\teval-mlogloss:2.269\n",
      "[181]\ttrain-mlogloss:1.58575\teval-mlogloss:2.26882\n",
      "[182]\ttrain-mlogloss:1.58283\teval-mlogloss:2.26878\n",
      "[183]\ttrain-mlogloss:1.5801\teval-mlogloss:2.26868\n",
      "[184]\ttrain-mlogloss:1.57742\teval-mlogloss:2.26865\n",
      "[185]\ttrain-mlogloss:1.57485\teval-mlogloss:2.26844\n",
      "[186]\ttrain-mlogloss:1.5722\teval-mlogloss:2.26843\n",
      "[187]\ttrain-mlogloss:1.56942\teval-mlogloss:2.26833\n",
      "[188]\ttrain-mlogloss:1.56697\teval-mlogloss:2.26815\n",
      "[189]\ttrain-mlogloss:1.56451\teval-mlogloss:2.26818\n",
      "[190]\ttrain-mlogloss:1.56166\teval-mlogloss:2.26818\n",
      "[191]\ttrain-mlogloss:1.55901\teval-mlogloss:2.26807\n",
      "[192]\ttrain-mlogloss:1.55689\teval-mlogloss:2.26789\n",
      "[193]\ttrain-mlogloss:1.55423\teval-mlogloss:2.26785\n",
      "[194]\ttrain-mlogloss:1.55173\teval-mlogloss:2.26776\n",
      "[195]\ttrain-mlogloss:1.54932\teval-mlogloss:2.26778\n",
      "[196]\ttrain-mlogloss:1.54672\teval-mlogloss:2.26776\n",
      "[197]\ttrain-mlogloss:1.54428\teval-mlogloss:2.26773\n",
      "[198]\ttrain-mlogloss:1.54168\teval-mlogloss:2.26755\n",
      "[199]\ttrain-mlogloss:1.53918\teval-mlogloss:2.26746\n",
      "[200]\ttrain-mlogloss:1.53662\teval-mlogloss:2.26746\n",
      "[201]\ttrain-mlogloss:1.53491\teval-mlogloss:2.26744\n",
      "[202]\ttrain-mlogloss:1.53229\teval-mlogloss:2.26732\n",
      "[203]\ttrain-mlogloss:1.52944\teval-mlogloss:2.2671\n",
      "[204]\ttrain-mlogloss:1.52682\teval-mlogloss:2.26695\n",
      "[205]\ttrain-mlogloss:1.52427\teval-mlogloss:2.26711\n",
      "[206]\ttrain-mlogloss:1.52187\teval-mlogloss:2.26715\n",
      "[207]\ttrain-mlogloss:1.51968\teval-mlogloss:2.26721\n",
      "[208]\ttrain-mlogloss:1.51696\teval-mlogloss:2.26706\n",
      "[209]\ttrain-mlogloss:1.51451\teval-mlogloss:2.2671\n",
      "[210]\ttrain-mlogloss:1.51185\teval-mlogloss:2.26703\n",
      "[211]\ttrain-mlogloss:1.50958\teval-mlogloss:2.26686\n",
      "[212]\ttrain-mlogloss:1.50747\teval-mlogloss:2.26686\n",
      "[213]\ttrain-mlogloss:1.50532\teval-mlogloss:2.2669\n",
      "[214]\ttrain-mlogloss:1.50294\teval-mlogloss:2.26678\n",
      "[215]\ttrain-mlogloss:1.50073\teval-mlogloss:2.26675\n",
      "[216]\ttrain-mlogloss:1.4981\teval-mlogloss:2.26675\n",
      "[217]\ttrain-mlogloss:1.49552\teval-mlogloss:2.2667\n",
      "[218]\ttrain-mlogloss:1.49329\teval-mlogloss:2.26672\n",
      "[219]\ttrain-mlogloss:1.49065\teval-mlogloss:2.26665\n",
      "[220]\ttrain-mlogloss:1.48817\teval-mlogloss:2.2667\n",
      "[221]\ttrain-mlogloss:1.48573\teval-mlogloss:2.26681\n",
      "[222]\ttrain-mlogloss:1.48314\teval-mlogloss:2.26674\n",
      "[223]\ttrain-mlogloss:1.48085\teval-mlogloss:2.2667\n",
      "[224]\ttrain-mlogloss:1.47856\teval-mlogloss:2.26664\n",
      "[225]\ttrain-mlogloss:1.47622\teval-mlogloss:2.26669\n",
      "[226]\ttrain-mlogloss:1.47389\teval-mlogloss:2.26657\n",
      "[227]\ttrain-mlogloss:1.47162\teval-mlogloss:2.2666\n",
      "[228]\ttrain-mlogloss:1.46936\teval-mlogloss:2.26656\n",
      "[229]\ttrain-mlogloss:1.46695\teval-mlogloss:2.26661\n",
      "[230]\ttrain-mlogloss:1.46478\teval-mlogloss:2.26664\n",
      "[231]\ttrain-mlogloss:1.46227\teval-mlogloss:2.26671\n",
      "[232]\ttrain-mlogloss:1.46\teval-mlogloss:2.26679\n",
      "[233]\ttrain-mlogloss:1.45756\teval-mlogloss:2.26683\n",
      "[234]\ttrain-mlogloss:1.45538\teval-mlogloss:2.26681\n",
      "[235]\ttrain-mlogloss:1.4533\teval-mlogloss:2.26674\n",
      "[236]\ttrain-mlogloss:1.45122\teval-mlogloss:2.26672\n",
      "[237]\ttrain-mlogloss:1.44902\teval-mlogloss:2.26658\n",
      "[238]\ttrain-mlogloss:1.44687\teval-mlogloss:2.26647\n",
      "[239]\ttrain-mlogloss:1.44433\teval-mlogloss:2.26651\n",
      "[240]\ttrain-mlogloss:1.44219\teval-mlogloss:2.26654\n",
      "[241]\ttrain-mlogloss:1.4398\teval-mlogloss:2.26651\n",
      "[242]\ttrain-mlogloss:1.43761\teval-mlogloss:2.26663\n",
      "[243]\ttrain-mlogloss:1.43544\teval-mlogloss:2.26655\n",
      "[244]\ttrain-mlogloss:1.43344\teval-mlogloss:2.26662\n",
      "[245]\ttrain-mlogloss:1.43133\teval-mlogloss:2.26646\n",
      "[246]\ttrain-mlogloss:1.42885\teval-mlogloss:2.26651\n",
      "[247]\ttrain-mlogloss:1.42669\teval-mlogloss:2.26648\n",
      "[248]\ttrain-mlogloss:1.42464\teval-mlogloss:2.2665\n",
      "[249]\ttrain-mlogloss:1.42248\teval-mlogloss:2.2664\n",
      "[250]\ttrain-mlogloss:1.42037\teval-mlogloss:2.26625\n",
      "[251]\ttrain-mlogloss:1.41845\teval-mlogloss:2.26623\n",
      "[252]\ttrain-mlogloss:1.41607\teval-mlogloss:2.2661\n",
      "[253]\ttrain-mlogloss:1.41376\teval-mlogloss:2.26615\n",
      "[254]\ttrain-mlogloss:1.41151\teval-mlogloss:2.26604\n",
      "[255]\ttrain-mlogloss:1.40949\teval-mlogloss:2.26594\n",
      "[256]\ttrain-mlogloss:1.40702\teval-mlogloss:2.26578\n",
      "[257]\ttrain-mlogloss:1.40494\teval-mlogloss:2.26581\n",
      "[258]\ttrain-mlogloss:1.40229\teval-mlogloss:2.26575\n",
      "[259]\ttrain-mlogloss:1.39991\teval-mlogloss:2.26579\n",
      "[260]\ttrain-mlogloss:1.39799\teval-mlogloss:2.26582\n",
      "[261]\ttrain-mlogloss:1.39573\teval-mlogloss:2.2657\n",
      "[262]\ttrain-mlogloss:1.39364\teval-mlogloss:2.26567\n",
      "[263]\ttrain-mlogloss:1.39159\teval-mlogloss:2.26565\n",
      "[264]\ttrain-mlogloss:1.38949\teval-mlogloss:2.26557\n",
      "[265]\ttrain-mlogloss:1.38745\teval-mlogloss:2.26563\n",
      "[266]\ttrain-mlogloss:1.38532\teval-mlogloss:2.26548\n",
      "[267]\ttrain-mlogloss:1.38302\teval-mlogloss:2.26543\n",
      "[268]\ttrain-mlogloss:1.38113\teval-mlogloss:2.26535\n",
      "[269]\ttrain-mlogloss:1.3791\teval-mlogloss:2.26526\n",
      "[270]\ttrain-mlogloss:1.377\teval-mlogloss:2.26521\n",
      "[271]\ttrain-mlogloss:1.37504\teval-mlogloss:2.26528\n",
      "[272]\ttrain-mlogloss:1.37296\teval-mlogloss:2.26515\n",
      "[273]\ttrain-mlogloss:1.3708\teval-mlogloss:2.26504\n",
      "[274]\ttrain-mlogloss:1.36878\teval-mlogloss:2.26514\n",
      "[275]\ttrain-mlogloss:1.36686\teval-mlogloss:2.26505\n",
      "[276]\ttrain-mlogloss:1.36476\teval-mlogloss:2.265\n",
      "[277]\ttrain-mlogloss:1.36274\teval-mlogloss:2.26495\n",
      "[278]\ttrain-mlogloss:1.36041\teval-mlogloss:2.26499\n",
      "[279]\ttrain-mlogloss:1.35832\teval-mlogloss:2.26508\n",
      "[280]\ttrain-mlogloss:1.35628\teval-mlogloss:2.26512\n",
      "[281]\ttrain-mlogloss:1.35424\teval-mlogloss:2.26499\n",
      "[282]\ttrain-mlogloss:1.35205\teval-mlogloss:2.26501\n",
      "[283]\ttrain-mlogloss:1.34992\teval-mlogloss:2.26503\n",
      "[284]\ttrain-mlogloss:1.34781\teval-mlogloss:2.26499\n",
      "[285]\ttrain-mlogloss:1.34583\teval-mlogloss:2.26495\n",
      "[286]\ttrain-mlogloss:1.34366\teval-mlogloss:2.26506\n",
      "[287]\ttrain-mlogloss:1.34174\teval-mlogloss:2.26501\n",
      "[288]\ttrain-mlogloss:1.33972\teval-mlogloss:2.26508\n",
      "[289]\ttrain-mlogloss:1.33788\teval-mlogloss:2.26515\n",
      "[290]\ttrain-mlogloss:1.33563\teval-mlogloss:2.26505\n",
      "[291]\ttrain-mlogloss:1.33358\teval-mlogloss:2.265\n",
      "[292]\ttrain-mlogloss:1.33201\teval-mlogloss:2.26491\n",
      "[293]\ttrain-mlogloss:1.32942\teval-mlogloss:2.26487\n",
      "[294]\ttrain-mlogloss:1.32722\teval-mlogloss:2.26486\n",
      "[295]\ttrain-mlogloss:1.32556\teval-mlogloss:2.26499\n",
      "[296]\ttrain-mlogloss:1.32343\teval-mlogloss:2.26516\n",
      "[297]\ttrain-mlogloss:1.32158\teval-mlogloss:2.26512\n",
      "[298]\ttrain-mlogloss:1.31983\teval-mlogloss:2.26522\n",
      "[299]\ttrain-mlogloss:1.31824\teval-mlogloss:2.26523\n",
      "[300]\ttrain-mlogloss:1.31621\teval-mlogloss:2.26528\n",
      "[301]\ttrain-mlogloss:1.31414\teval-mlogloss:2.26538\n",
      "[302]\ttrain-mlogloss:1.31198\teval-mlogloss:2.26534\n",
      "[303]\ttrain-mlogloss:1.30974\teval-mlogloss:2.26544\n",
      "[304]\ttrain-mlogloss:1.30783\teval-mlogloss:2.26541\n",
      "[305]\ttrain-mlogloss:1.30556\teval-mlogloss:2.26546\n",
      "[306]\ttrain-mlogloss:1.30344\teval-mlogloss:2.26551\n",
      "[307]\ttrain-mlogloss:1.30188\teval-mlogloss:2.26551\n",
      "[308]\ttrain-mlogloss:1.30009\teval-mlogloss:2.26558\n",
      "[309]\ttrain-mlogloss:1.29832\teval-mlogloss:2.26568\n",
      "[310]\ttrain-mlogloss:1.29638\teval-mlogloss:2.26569\n",
      "[311]\ttrain-mlogloss:1.29477\teval-mlogloss:2.26571\n",
      "[312]\ttrain-mlogloss:1.29282\teval-mlogloss:2.2657\n",
      "[313]\ttrain-mlogloss:1.29088\teval-mlogloss:2.26581\n",
      "[314]\ttrain-mlogloss:1.28878\teval-mlogloss:2.26592\n",
      "Stopping. Best iteration:\n",
      "[294]\ttrain-mlogloss:1.32722\teval-mlogloss:2.26486\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_boost_round = 500\n",
    "early_stopping_rounds = 20\n",
    "\n",
    "watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "gbm = xgb.train(params, dtrain, num_boost_round, evals=watchlist, early_stopping_rounds=early_stopping_rounds, verbose_eval=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "from operator import itemgetter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = gbm.predict(xgb.DMatrix(X_test), ntree_limit=gbm.best_iteration)\n",
    "score = log_loss(y_test.tolist(), check)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.264870859669824"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.10541765, 0.06238316, 0.06603902, ..., 0.05622305, 0.03493218,\n",
       "        0.09288632],\n",
       "       [0.10069416, 0.13546373, 0.08316234, ..., 0.12144317, 0.11809093,\n",
       "        0.06743475],\n",
       "       [0.15610892, 0.06783275, 0.02282487, ..., 0.02586291, 0.02284555,\n",
       "        0.03208927],\n",
       "       ...,\n",
       "       [0.1651624 , 0.12221807, 0.02974415, ..., 0.01973143, 0.02021362,\n",
       "        0.04532626],\n",
       "       [0.07014556, 0.0504574 , 0.03442922, ..., 0.0979208 , 0.17365387,\n",
       "        0.04037686],\n",
       "       [0.08604199, 0.05304288, 0.04915845, ..., 0.11270293, 0.23014499,\n",
       "        0.07122065]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_map(features):\n",
    "    outfile = open('xgb.fmap', 'w')\n",
    "    for i, feat in enumerate(features):\n",
    "        outfile.write('{0}\\t{1}\\tq\\n'.format(i, feat))\n",
    "    outfile.close()\n",
    "\n",
    "\n",
    "def get_importance(gbm, features):\n",
    "    create_feature_map(features)\n",
    "    importance = gbm.get_fscore(fmap='xgb.fmap')\n",
    "    importance = sorted(importance.items(), key=itemgetter(1), reverse=True)\n",
    "    return importance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = get_importance(gbm, magyarazo_valtozok)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('events_per_day', 13206),\n",
       " ('device_model', 12925),\n",
       " ('label_22222', 7583),\n",
       " ('label_i_22222', 7514),\n",
       " ('label_i_714', 7324),\n",
       " ('label_i_128', 7052),\n",
       " ('label_i_179', 6812),\n",
       " ('label_i_721', 6722),\n",
       " ('phone_brand_eng', 6536),\n",
       " ('label_i_306', 6256),\n",
       " ('label_i_713', 5882),\n",
       " ('label_i_549', 5821),\n",
       " ('label_i_710', 5799),\n",
       " ('label_i_303', 5777),\n",
       " ('label_i_251', 5636),\n",
       " ('label_548', 5386),\n",
       " ('label_i_548', 5282),\n",
       " ('label_i_302', 5227),\n",
       " ('label_713', 5216),\n",
       " ('label_i_786', 5181),\n",
       " ('label_i_172', 5117),\n",
       " ('events_num', 5065),\n",
       " ('label_i_704', 5062),\n",
       " ('label_128', 5051),\n",
       " ('label_549', 4975),\n",
       " ('label_721', 4941),\n",
       " ('label_306', 4867),\n",
       " ('label_302', 4846),\n",
       " ('label_714', 4689),\n",
       " ('label_179', 4672),\n",
       " ('label_704', 4532),\n",
       " ('label_i_405', 4507),\n",
       " ('label_i_252', 4429),\n",
       " ('label_303', 4415),\n",
       " ('label_263', 4207),\n",
       " ('label_i_775', 4170),\n",
       " ('label_i_263', 4117),\n",
       " ('label_252', 4025),\n",
       " ('label_710', 4017),\n",
       " ('label_i_783', 3989),\n",
       " ('label_172', 3902),\n",
       " ('label_i_730', 3868),\n",
       " ('label_i_1007', 3829),\n",
       " ('label_251', 3594),\n",
       " ('label_i_756', 3579),\n",
       " ('label_i_959', 3405),\n",
       " ('label_786', 3214),\n",
       " ('label_405', 3192),\n",
       " ('label_i_782', 3141),\n",
       " ('label_1007', 2880),\n",
       " ('label_959', 2551),\n",
       " ('label_i_777', 2549),\n",
       " ('label_783', 2429),\n",
       " ('label_775', 2421),\n",
       " ('label_i_779', 2345),\n",
       " ('label_756', 2200),\n",
       " ('label_i_787', 2194),\n",
       " ('label_i_757', 2095),\n",
       " ('label_730', 2047),\n",
       " ('label_782', 1879),\n",
       " ('label_777', 1343),\n",
       " ('label_779', 1309),\n",
       " ('label_787', 1069),\n",
       " ('label_i_960', 940),\n",
       " ('label_757', 855),\n",
       " ('label_960', 667)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
