{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # pandas\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  XGBoost\n",
    "https://www.kaggle.com/tilii7/xgboost-simple-starter-more-features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akos/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#Importing Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.externals import joblib\n",
    "from sklearn import metrics\n",
    "import xgboost as xgb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../datasets/train1_60labels.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>device_id</th>\n",
       "      <th>events_num</th>\n",
       "      <th>min_timestamp</th>\n",
       "      <th>max_timestamp</th>\n",
       "      <th>events_per_day</th>\n",
       "      <th>label_548</th>\n",
       "      <th>label_i_548</th>\n",
       "      <th>label_704</th>\n",
       "      <th>label_i_704</th>\n",
       "      <th>...</th>\n",
       "      <th>label_168</th>\n",
       "      <th>label_i_168</th>\n",
       "      <th>label_22222</th>\n",
       "      <th>label_i_22222</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>group</th>\n",
       "      <th>phone_brand</th>\n",
       "      <th>device_model</th>\n",
       "      <th>phone_brand_eng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-8260683887967679142</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-05-01 14:23:37</td>\n",
       "      <td>2016-05-01 14:23:37</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>79</td>\n",
       "      <td>M</td>\n",
       "      <td>35</td>\n",
       "      <td>M32-38</td>\n",
       "      <td>小米</td>\n",
       "      <td>MI 2</td>\n",
       "      <td>Xiaomi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7477216237379271436</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-05-04 14:08:17</td>\n",
       "      <td>2016-05-06 18:51:15</td>\n",
       "      <td>0.065502</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>25</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>42</td>\n",
       "      <td>F</td>\n",
       "      <td>37</td>\n",
       "      <td>F33-42</td>\n",
       "      <td>华为</td>\n",
       "      <td>荣耀6 plus</td>\n",
       "      <td>Huawei</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>6352067998666467520</td>\n",
       "      <td>11</td>\n",
       "      <td>2016-05-03 22:14:30</td>\n",
       "      <td>2016-05-05 17:27:58</td>\n",
       "      <td>0.072820</td>\n",
       "      <td>70</td>\n",
       "      <td>34</td>\n",
       "      <td>57</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>149</td>\n",
       "      <td>57</td>\n",
       "      <td>M</td>\n",
       "      <td>32</td>\n",
       "      <td>M32-38</td>\n",
       "      <td>华为</td>\n",
       "      <td>荣耀畅玩4X</td>\n",
       "      <td>Huawei</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1508636020748379883</td>\n",
       "      <td>5</td>\n",
       "      <td>2016-05-01 12:41:38</td>\n",
       "      <td>2016-05-05 12:34:15</td>\n",
       "      <td>0.198975</td>\n",
       "      <td>50</td>\n",
       "      <td>39</td>\n",
       "      <td>38</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>51</td>\n",
       "      <td>F</td>\n",
       "      <td>28</td>\n",
       "      <td>F27-28</td>\n",
       "      <td>华为</td>\n",
       "      <td>荣耀畅玩4X</td>\n",
       "      <td>Huawei</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-6876541075223249434</td>\n",
       "      <td>6</td>\n",
       "      <td>2016-05-01 02:51:41</td>\n",
       "      <td>2016-05-06 16:30:01</td>\n",
       "      <td>0.094715</td>\n",
       "      <td>63</td>\n",
       "      <td>187</td>\n",
       "      <td>46</td>\n",
       "      <td>162</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>72</td>\n",
       "      <td>313</td>\n",
       "      <td>M</td>\n",
       "      <td>75</td>\n",
       "      <td>M39+</td>\n",
       "      <td>魅族</td>\n",
       "      <td>魅蓝NOTE</td>\n",
       "      <td>Meizu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 134 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0            device_id  events_num        min_timestamp  \\\n",
       "0           0 -8260683887967679142           1  2016-05-01 14:23:37   \n",
       "1           1  7477216237379271436           3  2016-05-04 14:08:17   \n",
       "2           2  6352067998666467520          11  2016-05-03 22:14:30   \n",
       "3           3  1508636020748379883           5  2016-05-01 12:41:38   \n",
       "4           4 -6876541075223249434           6  2016-05-01 02:51:41   \n",
       "\n",
       "         max_timestamp  events_per_day  label_548  label_i_548  label_704  \\\n",
       "0  2016-05-01 14:23:37        0.000000          5           30          3   \n",
       "1  2016-05-06 18:51:15        0.065502         31           29         25   \n",
       "2  2016-05-05 17:27:58        0.072820         70           34         57   \n",
       "3  2016-05-05 12:34:15        0.198975         50           39         38   \n",
       "4  2016-05-06 16:30:01        0.094715         63          187         46   \n",
       "\n",
       "   label_i_704       ...         label_168  label_i_168  label_22222  \\\n",
       "0           24       ...                 0            3            3   \n",
       "1           17       ...                 0            0           12   \n",
       "2           19       ...                 0            0          149   \n",
       "3           36       ...                 0            0           46   \n",
       "4          162       ...                 0           12           72   \n",
       "\n",
       "   label_i_22222  gender  age   group  phone_brand  device_model  \\\n",
       "0             79       M   35  M32-38           小米          MI 2   \n",
       "1             42       F   37  F33-42           华为      荣耀6 plus   \n",
       "2             57       M   32  M32-38           华为        荣耀畅玩4X   \n",
       "3             51       F   28  F27-28           华为        荣耀畅玩4X   \n",
       "4            313       M   75    M39+           魅族        魅蓝NOTE   \n",
       "\n",
       "   phone_brand_eng  \n",
       "0           Xiaomi  \n",
       "1           Huawei  \n",
       "2           Huawei  \n",
       "3           Huawei  \n",
       "4            Meizu  \n",
       "\n",
       "[5 rows x 134 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   num_boost_round = 500\n",
    "    early_stopping_rounds = 20\n",
    "    test_size = 0.2\n",
    "\n",
    "    X_train, X_valid = train_test_split(train, test_size=test_size, random_state=random_state)\n",
    "    print('Length train:', len(X_train.index))\n",
    "    print('Length valid:', len(X_valid.index))\n",
    "    y_train = X_train[target]\n",
    "    y_valid = X_valid[target]\n",
    "    dtrain = xgb.DMatrix(X_train[features], y_train)\n",
    "    dvalid = xgb.DMatrix(X_valid[features], y_valid)\n",
    "\n",
    "    watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "    gbm = xgb.train(params, dtrain, num_boost_round, evals=watchlist, early_stopping_rounds=early_stopping_rounds, verbose_eval=True)\n",
    "\n",
    "    print(\"Validating...\")\n",
    "    check = gbm.predict(xgb.DMatrix(X_valid[features]), ntree_limit=gbm.best_iteration)\n",
    "    score = log_loss(y_valid.tolist(), check)\n",
    "\n",
    "    imp = get_importance(gbm, features)\n",
    "    print('Importance array: ', imp)\n",
    "\n",
    "    print(\"Predict test set...\")\n",
    "    test_prediction = gbm.predict(xgb.DMatrix(test[features]), ntree_limit=gbm.best_iteration)\n",
    "\n",
    "    print('Training time: {} minutes'.format(round((time.time() - start_time)/60, 2)))\n",
    "    return test_prediction.tolist(), score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor = pd.factorize(df_train['phone_brand_eng'])\n",
    "df_train.phone_brand_eng = factor[0]\n",
    "definitions_phone_brand_eng = factor[1]\n",
    "factor = pd.factorize(df_train['device_model'])\n",
    "df_train.device_model = factor[0]\n",
    "definitions_device_model = factor[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor = pd.factorize(df_train['group'])\n",
    "df_train.group = factor[0]\n",
    "definitions = factor[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "magyarazo_valtozok = []\n",
    "for m in df_train.columns:\n",
    "    if m not in ['Unnamed: 0', 'device_id', 'min_timestamp', 'max_timestamp','gender', 'age', 'group', 'phone_brand' ]:\n",
    "        magyarazo_valtozok += [m]\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_train[magyarazo_valtozok], df_train['group'], test_size=0.2,random_state=109) # 90% training and 10% test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akos/anaconda3/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(X_train, y_train)\n",
    "dvalid = xgb.DMatrix(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>device_id</th>\n",
       "      <th>events_num</th>\n",
       "      <th>min_timestamp</th>\n",
       "      <th>max_timestamp</th>\n",
       "      <th>events_per_day</th>\n",
       "      <th>label_548</th>\n",
       "      <th>label_i_548</th>\n",
       "      <th>label_704</th>\n",
       "      <th>label_i_704</th>\n",
       "      <th>...</th>\n",
       "      <th>label_168</th>\n",
       "      <th>label_i_168</th>\n",
       "      <th>label_22222</th>\n",
       "      <th>label_i_22222</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>group</th>\n",
       "      <th>phone_brand</th>\n",
       "      <th>device_model</th>\n",
       "      <th>phone_brand_eng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-8260683887967679142</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-05-01 14:23:37</td>\n",
       "      <td>2016-05-01 14:23:37</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>79</td>\n",
       "      <td>M</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>小米</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7477216237379271436</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-05-04 14:08:17</td>\n",
       "      <td>2016-05-06 18:51:15</td>\n",
       "      <td>0.065502</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>25</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>42</td>\n",
       "      <td>F</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>华为</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>6352067998666467520</td>\n",
       "      <td>11</td>\n",
       "      <td>2016-05-03 22:14:30</td>\n",
       "      <td>2016-05-05 17:27:58</td>\n",
       "      <td>0.072820</td>\n",
       "      <td>70</td>\n",
       "      <td>34</td>\n",
       "      <td>57</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>149</td>\n",
       "      <td>57</td>\n",
       "      <td>M</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>华为</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1508636020748379883</td>\n",
       "      <td>5</td>\n",
       "      <td>2016-05-01 12:41:38</td>\n",
       "      <td>2016-05-05 12:34:15</td>\n",
       "      <td>0.198975</td>\n",
       "      <td>50</td>\n",
       "      <td>39</td>\n",
       "      <td>38</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>51</td>\n",
       "      <td>F</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>华为</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-6876541075223249434</td>\n",
       "      <td>6</td>\n",
       "      <td>2016-05-01 02:51:41</td>\n",
       "      <td>2016-05-06 16:30:01</td>\n",
       "      <td>0.094715</td>\n",
       "      <td>63</td>\n",
       "      <td>187</td>\n",
       "      <td>46</td>\n",
       "      <td>162</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>72</td>\n",
       "      <td>313</td>\n",
       "      <td>M</td>\n",
       "      <td>75</td>\n",
       "      <td>3</td>\n",
       "      <td>魅族</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 134 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0            device_id  events_num        min_timestamp  \\\n",
       "0           0 -8260683887967679142           1  2016-05-01 14:23:37   \n",
       "1           1  7477216237379271436           3  2016-05-04 14:08:17   \n",
       "2           2  6352067998666467520          11  2016-05-03 22:14:30   \n",
       "3           3  1508636020748379883           5  2016-05-01 12:41:38   \n",
       "4           4 -6876541075223249434           6  2016-05-01 02:51:41   \n",
       "\n",
       "         max_timestamp  events_per_day  label_548  label_i_548  label_704  \\\n",
       "0  2016-05-01 14:23:37        0.000000          5           30          3   \n",
       "1  2016-05-06 18:51:15        0.065502         31           29         25   \n",
       "2  2016-05-05 17:27:58        0.072820         70           34         57   \n",
       "3  2016-05-05 12:34:15        0.198975         50           39         38   \n",
       "4  2016-05-06 16:30:01        0.094715         63          187         46   \n",
       "\n",
       "   label_i_704       ...         label_168  label_i_168  label_22222  \\\n",
       "0           24       ...                 0            3            3   \n",
       "1           17       ...                 0            0           12   \n",
       "2           19       ...                 0            0          149   \n",
       "3           36       ...                 0            0           46   \n",
       "4          162       ...                 0           12           72   \n",
       "\n",
       "   label_i_22222  gender  age  group  phone_brand  device_model  \\\n",
       "0             79       M   35      0           小米             0   \n",
       "1             42       F   37      1           华为             1   \n",
       "2             57       M   32      0           华为             2   \n",
       "3             51       F   28      2           华为             2   \n",
       "4            313       M   75      3           魅族             3   \n",
       "\n",
       "   phone_brand_eng  \n",
       "0                0  \n",
       "1                1  \n",
       "2                1  \n",
       "3                1  \n",
       "4                2  \n",
       "\n",
       "[5 rows x 134 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb parameterek ... nem tudom, hogy mi hogy számít...\n",
    "\n",
    "eta = 0.025\n",
    "max_depth = 7\n",
    "subsample = 0.75\n",
    "colsample_bytree = 0.75\n",
    "random_state=123\n",
    "params = {\n",
    "        \"objective\": \"multi:softprob\",\n",
    "        \"num_class\": 12,\n",
    "        \"booster\" : \"gbtree\",\n",
    "        \"eval_metric\": \"mlogloss\",\n",
    "        \"eta\": eta,\n",
    "        \"max_depth\": max_depth,\n",
    "        \"subsample\": subsample,\n",
    "        \"colsample_bytree\": colsample_bytree,\n",
    "        \"silent\": 1,\n",
    "        \"seed\": random_state,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:2.47182\teval-mlogloss:2.47846\n",
      "Multiple eval metrics have been passed: 'eval-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until eval-mlogloss hasn't improved in 20 rounds.\n",
      "[1]\ttrain-mlogloss:2.45894\teval-mlogloss:2.47253\n",
      "[2]\ttrain-mlogloss:2.44659\teval-mlogloss:2.46678\n",
      "[3]\ttrain-mlogloss:2.43466\teval-mlogloss:2.46155\n",
      "[4]\ttrain-mlogloss:2.42302\teval-mlogloss:2.45626\n",
      "[5]\ttrain-mlogloss:2.4114\teval-mlogloss:2.45138\n",
      "[6]\ttrain-mlogloss:2.40016\teval-mlogloss:2.44655\n",
      "[7]\ttrain-mlogloss:2.3887\teval-mlogloss:2.44175\n",
      "[8]\ttrain-mlogloss:2.37781\teval-mlogloss:2.43706\n",
      "[9]\ttrain-mlogloss:2.36756\teval-mlogloss:2.43233\n",
      "[10]\ttrain-mlogloss:2.35691\teval-mlogloss:2.42794\n",
      "[11]\ttrain-mlogloss:2.34654\teval-mlogloss:2.4236\n",
      "[12]\ttrain-mlogloss:2.33638\teval-mlogloss:2.41932\n",
      "[13]\ttrain-mlogloss:2.32654\teval-mlogloss:2.41521\n",
      "[14]\ttrain-mlogloss:2.31677\teval-mlogloss:2.41111\n",
      "[15]\ttrain-mlogloss:2.30711\teval-mlogloss:2.40736\n",
      "[16]\ttrain-mlogloss:2.29768\teval-mlogloss:2.40373\n",
      "[17]\ttrain-mlogloss:2.28852\teval-mlogloss:2.39999\n",
      "[18]\ttrain-mlogloss:2.27966\teval-mlogloss:2.39629\n",
      "[19]\ttrain-mlogloss:2.27045\teval-mlogloss:2.39268\n",
      "[20]\ttrain-mlogloss:2.26158\teval-mlogloss:2.38931\n",
      "[21]\ttrain-mlogloss:2.25275\teval-mlogloss:2.38601\n",
      "[22]\ttrain-mlogloss:2.24422\teval-mlogloss:2.38295\n",
      "[23]\ttrain-mlogloss:2.23599\teval-mlogloss:2.37995\n",
      "[24]\ttrain-mlogloss:2.22777\teval-mlogloss:2.37696\n",
      "[25]\ttrain-mlogloss:2.21972\teval-mlogloss:2.37401\n",
      "[26]\ttrain-mlogloss:2.21169\teval-mlogloss:2.37101\n",
      "[27]\ttrain-mlogloss:2.20383\teval-mlogloss:2.36833\n",
      "[28]\ttrain-mlogloss:2.19578\teval-mlogloss:2.36557\n",
      "[29]\ttrain-mlogloss:2.18784\teval-mlogloss:2.36275\n",
      "[30]\ttrain-mlogloss:2.18026\teval-mlogloss:2.36012\n",
      "[31]\ttrain-mlogloss:2.17251\teval-mlogloss:2.35741\n",
      "[32]\ttrain-mlogloss:2.16475\teval-mlogloss:2.35504\n",
      "[33]\ttrain-mlogloss:2.15723\teval-mlogloss:2.35243\n",
      "[34]\ttrain-mlogloss:2.14992\teval-mlogloss:2.34984\n",
      "[35]\ttrain-mlogloss:2.14238\teval-mlogloss:2.34772\n",
      "[36]\ttrain-mlogloss:2.13526\teval-mlogloss:2.34548\n",
      "[37]\ttrain-mlogloss:2.1284\teval-mlogloss:2.34334\n",
      "[38]\ttrain-mlogloss:2.12117\teval-mlogloss:2.34131\n",
      "[39]\ttrain-mlogloss:2.11417\teval-mlogloss:2.33923\n",
      "[40]\ttrain-mlogloss:2.10723\teval-mlogloss:2.33707\n",
      "[41]\ttrain-mlogloss:2.10091\teval-mlogloss:2.33494\n",
      "[42]\ttrain-mlogloss:2.09427\teval-mlogloss:2.33289\n",
      "[43]\ttrain-mlogloss:2.0877\teval-mlogloss:2.33093\n",
      "[44]\ttrain-mlogloss:2.08113\teval-mlogloss:2.32917\n",
      "[45]\ttrain-mlogloss:2.07448\teval-mlogloss:2.32729\n",
      "[46]\ttrain-mlogloss:2.06806\teval-mlogloss:2.3255\n",
      "[47]\ttrain-mlogloss:2.06218\teval-mlogloss:2.32386\n",
      "[48]\ttrain-mlogloss:2.05574\teval-mlogloss:2.3221\n",
      "[49]\ttrain-mlogloss:2.0492\teval-mlogloss:2.32016\n",
      "[50]\ttrain-mlogloss:2.04298\teval-mlogloss:2.31837\n",
      "[51]\ttrain-mlogloss:2.03675\teval-mlogloss:2.31668\n",
      "[52]\ttrain-mlogloss:2.0304\teval-mlogloss:2.31513\n",
      "[53]\ttrain-mlogloss:2.02448\teval-mlogloss:2.31351\n",
      "[54]\ttrain-mlogloss:2.01862\teval-mlogloss:2.31203\n",
      "[55]\ttrain-mlogloss:2.01263\teval-mlogloss:2.31081\n",
      "[56]\ttrain-mlogloss:2.00676\teval-mlogloss:2.30946\n",
      "[57]\ttrain-mlogloss:2.00094\teval-mlogloss:2.308\n",
      "[58]\ttrain-mlogloss:1.99549\teval-mlogloss:2.30666\n",
      "[59]\ttrain-mlogloss:1.98992\teval-mlogloss:2.30525\n",
      "[60]\ttrain-mlogloss:1.9845\teval-mlogloss:2.30392\n",
      "[61]\ttrain-mlogloss:1.97888\teval-mlogloss:2.30281\n",
      "[62]\ttrain-mlogloss:1.9735\teval-mlogloss:2.30151\n",
      "[63]\ttrain-mlogloss:1.968\teval-mlogloss:2.30018\n",
      "[64]\ttrain-mlogloss:1.96271\teval-mlogloss:2.29904\n",
      "[65]\ttrain-mlogloss:1.95731\teval-mlogloss:2.29783\n",
      "[66]\ttrain-mlogloss:1.95204\teval-mlogloss:2.2967\n",
      "[67]\ttrain-mlogloss:1.9467\teval-mlogloss:2.29543\n",
      "[68]\ttrain-mlogloss:1.94155\teval-mlogloss:2.2943\n",
      "[69]\ttrain-mlogloss:1.93654\teval-mlogloss:2.29322\n",
      "[70]\ttrain-mlogloss:1.93165\teval-mlogloss:2.29213\n",
      "[71]\ttrain-mlogloss:1.92667\teval-mlogloss:2.29115\n",
      "[72]\ttrain-mlogloss:1.92135\teval-mlogloss:2.28998\n",
      "[73]\ttrain-mlogloss:1.91639\teval-mlogloss:2.28882\n",
      "[74]\ttrain-mlogloss:1.91145\teval-mlogloss:2.2877\n",
      "[75]\ttrain-mlogloss:1.90678\teval-mlogloss:2.28683\n",
      "[76]\ttrain-mlogloss:1.90163\teval-mlogloss:2.28577\n",
      "[77]\ttrain-mlogloss:1.89677\teval-mlogloss:2.28488\n",
      "[78]\ttrain-mlogloss:1.89164\teval-mlogloss:2.28386\n",
      "[79]\ttrain-mlogloss:1.88667\teval-mlogloss:2.28295\n",
      "[80]\ttrain-mlogloss:1.88165\teval-mlogloss:2.28187\n",
      "[81]\ttrain-mlogloss:1.87714\teval-mlogloss:2.2811\n",
      "[82]\ttrain-mlogloss:1.87278\teval-mlogloss:2.28032\n",
      "[83]\ttrain-mlogloss:1.86836\teval-mlogloss:2.27964\n",
      "[84]\ttrain-mlogloss:1.86351\teval-mlogloss:2.2788\n",
      "[85]\ttrain-mlogloss:1.85873\teval-mlogloss:2.2781\n",
      "[86]\ttrain-mlogloss:1.85428\teval-mlogloss:2.27738\n",
      "[87]\ttrain-mlogloss:1.84941\teval-mlogloss:2.27653\n",
      "[88]\ttrain-mlogloss:1.84491\teval-mlogloss:2.27578\n",
      "[89]\ttrain-mlogloss:1.84031\teval-mlogloss:2.2751\n",
      "[90]\ttrain-mlogloss:1.83581\teval-mlogloss:2.27422\n",
      "[91]\ttrain-mlogloss:1.83118\teval-mlogloss:2.27336\n",
      "[92]\ttrain-mlogloss:1.82705\teval-mlogloss:2.2727\n",
      "[93]\ttrain-mlogloss:1.82276\teval-mlogloss:2.27193\n",
      "[94]\ttrain-mlogloss:1.81826\teval-mlogloss:2.27115\n",
      "[95]\ttrain-mlogloss:1.81399\teval-mlogloss:2.27051\n",
      "[96]\ttrain-mlogloss:1.80994\teval-mlogloss:2.26988\n",
      "[97]\ttrain-mlogloss:1.80551\teval-mlogloss:2.26911\n",
      "[98]\ttrain-mlogloss:1.8012\teval-mlogloss:2.26851\n",
      "[99]\ttrain-mlogloss:1.7969\teval-mlogloss:2.26798\n",
      "[100]\ttrain-mlogloss:1.79286\teval-mlogloss:2.2672\n",
      "[101]\ttrain-mlogloss:1.78877\teval-mlogloss:2.26646\n",
      "[102]\ttrain-mlogloss:1.78453\teval-mlogloss:2.26558\n",
      "[103]\ttrain-mlogloss:1.78036\teval-mlogloss:2.265\n",
      "[104]\ttrain-mlogloss:1.7762\teval-mlogloss:2.26451\n",
      "[105]\ttrain-mlogloss:1.77228\teval-mlogloss:2.2641\n",
      "[106]\ttrain-mlogloss:1.76829\teval-mlogloss:2.26348\n",
      "[107]\ttrain-mlogloss:1.76404\teval-mlogloss:2.26274\n",
      "[108]\ttrain-mlogloss:1.76028\teval-mlogloss:2.26221\n",
      "[109]\ttrain-mlogloss:1.75632\teval-mlogloss:2.2616\n",
      "[110]\ttrain-mlogloss:1.75251\teval-mlogloss:2.26096\n",
      "[111]\ttrain-mlogloss:1.74869\teval-mlogloss:2.26026\n",
      "[112]\ttrain-mlogloss:1.74475\teval-mlogloss:2.25971\n",
      "[113]\ttrain-mlogloss:1.74093\teval-mlogloss:2.25915\n",
      "[114]\ttrain-mlogloss:1.73691\teval-mlogloss:2.25844\n",
      "[115]\ttrain-mlogloss:1.73334\teval-mlogloss:2.25798\n",
      "[116]\ttrain-mlogloss:1.72931\teval-mlogloss:2.25758\n",
      "[117]\ttrain-mlogloss:1.7256\teval-mlogloss:2.2569\n",
      "[118]\ttrain-mlogloss:1.72202\teval-mlogloss:2.25649\n",
      "[119]\ttrain-mlogloss:1.71831\teval-mlogloss:2.25622\n",
      "[120]\ttrain-mlogloss:1.71492\teval-mlogloss:2.25574\n",
      "[121]\ttrain-mlogloss:1.71105\teval-mlogloss:2.25534\n",
      "[122]\ttrain-mlogloss:1.70705\teval-mlogloss:2.25489\n",
      "[123]\ttrain-mlogloss:1.70315\teval-mlogloss:2.25449\n",
      "[124]\ttrain-mlogloss:1.6992\teval-mlogloss:2.25416\n",
      "[125]\ttrain-mlogloss:1.69583\teval-mlogloss:2.25365\n",
      "[126]\ttrain-mlogloss:1.69183\teval-mlogloss:2.25335\n",
      "[127]\ttrain-mlogloss:1.68847\teval-mlogloss:2.25293\n",
      "[128]\ttrain-mlogloss:1.68497\teval-mlogloss:2.25258\n",
      "[129]\ttrain-mlogloss:1.68122\teval-mlogloss:2.25221\n",
      "[130]\ttrain-mlogloss:1.67761\teval-mlogloss:2.25178\n",
      "[131]\ttrain-mlogloss:1.67431\teval-mlogloss:2.25146\n",
      "[132]\ttrain-mlogloss:1.67094\teval-mlogloss:2.25102\n",
      "[133]\ttrain-mlogloss:1.66737\teval-mlogloss:2.25068\n",
      "[134]\ttrain-mlogloss:1.66403\teval-mlogloss:2.25039\n",
      "[135]\ttrain-mlogloss:1.66084\teval-mlogloss:2.24981\n",
      "[136]\ttrain-mlogloss:1.65751\teval-mlogloss:2.24966\n",
      "[137]\ttrain-mlogloss:1.65377\teval-mlogloss:2.24941\n",
      "[138]\ttrain-mlogloss:1.6505\teval-mlogloss:2.24904\n",
      "[139]\ttrain-mlogloss:1.64708\teval-mlogloss:2.24861\n",
      "[140]\ttrain-mlogloss:1.64383\teval-mlogloss:2.24826\n",
      "[141]\ttrain-mlogloss:1.64062\teval-mlogloss:2.24799\n",
      "[142]\ttrain-mlogloss:1.63748\teval-mlogloss:2.24764\n",
      "[143]\ttrain-mlogloss:1.63437\teval-mlogloss:2.24749\n",
      "[144]\ttrain-mlogloss:1.63107\teval-mlogloss:2.24714\n",
      "[145]\ttrain-mlogloss:1.62772\teval-mlogloss:2.24691\n",
      "[146]\ttrain-mlogloss:1.62424\teval-mlogloss:2.24664\n",
      "[147]\ttrain-mlogloss:1.62056\teval-mlogloss:2.24642\n",
      "[148]\ttrain-mlogloss:1.61728\teval-mlogloss:2.24617\n",
      "[149]\ttrain-mlogloss:1.61421\teval-mlogloss:2.24588\n",
      "[150]\ttrain-mlogloss:1.61084\teval-mlogloss:2.24557\n",
      "[151]\ttrain-mlogloss:1.60746\teval-mlogloss:2.24542\n",
      "[152]\ttrain-mlogloss:1.60409\teval-mlogloss:2.24519\n",
      "[153]\ttrain-mlogloss:1.60068\teval-mlogloss:2.24502\n",
      "[154]\ttrain-mlogloss:1.59745\teval-mlogloss:2.24476\n",
      "[155]\ttrain-mlogloss:1.59438\teval-mlogloss:2.24442\n",
      "[156]\ttrain-mlogloss:1.59113\teval-mlogloss:2.24413\n",
      "[157]\ttrain-mlogloss:1.58761\teval-mlogloss:2.244\n",
      "[158]\ttrain-mlogloss:1.58437\teval-mlogloss:2.24374\n",
      "[159]\ttrain-mlogloss:1.58104\teval-mlogloss:2.24333\n",
      "[160]\ttrain-mlogloss:1.57791\teval-mlogloss:2.24305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[161]\ttrain-mlogloss:1.57461\teval-mlogloss:2.24266\n",
      "[162]\ttrain-mlogloss:1.5717\teval-mlogloss:2.2425\n",
      "[163]\ttrain-mlogloss:1.56856\teval-mlogloss:2.24218\n",
      "[164]\ttrain-mlogloss:1.56516\teval-mlogloss:2.24181\n",
      "[165]\ttrain-mlogloss:1.56173\teval-mlogloss:2.24146\n",
      "[166]\ttrain-mlogloss:1.5588\teval-mlogloss:2.24126\n",
      "[167]\ttrain-mlogloss:1.55589\teval-mlogloss:2.24118\n",
      "[168]\ttrain-mlogloss:1.55286\teval-mlogloss:2.24091\n",
      "[169]\ttrain-mlogloss:1.54975\teval-mlogloss:2.24068\n",
      "[170]\ttrain-mlogloss:1.54684\teval-mlogloss:2.2404\n",
      "[171]\ttrain-mlogloss:1.54391\teval-mlogloss:2.24006\n",
      "[172]\ttrain-mlogloss:1.54094\teval-mlogloss:2.23973\n",
      "[173]\ttrain-mlogloss:1.53813\teval-mlogloss:2.23959\n",
      "[174]\ttrain-mlogloss:1.53523\teval-mlogloss:2.23941\n",
      "[175]\ttrain-mlogloss:1.53239\teval-mlogloss:2.23914\n",
      "[176]\ttrain-mlogloss:1.52953\teval-mlogloss:2.23881\n",
      "[177]\ttrain-mlogloss:1.52645\teval-mlogloss:2.23877\n",
      "[178]\ttrain-mlogloss:1.52358\teval-mlogloss:2.23861\n",
      "[179]\ttrain-mlogloss:1.5207\teval-mlogloss:2.23848\n",
      "[180]\ttrain-mlogloss:1.51784\teval-mlogloss:2.23817\n",
      "[181]\ttrain-mlogloss:1.51491\teval-mlogloss:2.23791\n",
      "[182]\ttrain-mlogloss:1.51211\teval-mlogloss:2.23782\n",
      "[183]\ttrain-mlogloss:1.50907\teval-mlogloss:2.23775\n",
      "[184]\ttrain-mlogloss:1.5058\teval-mlogloss:2.23751\n",
      "[185]\ttrain-mlogloss:1.50319\teval-mlogloss:2.2374\n",
      "[186]\ttrain-mlogloss:1.50015\teval-mlogloss:2.23735\n",
      "[187]\ttrain-mlogloss:1.49717\teval-mlogloss:2.23734\n",
      "[188]\ttrain-mlogloss:1.49446\teval-mlogloss:2.23719\n",
      "[189]\ttrain-mlogloss:1.49152\teval-mlogloss:2.23722\n",
      "[190]\ttrain-mlogloss:1.48856\teval-mlogloss:2.23718\n",
      "[191]\ttrain-mlogloss:1.48552\teval-mlogloss:2.23721\n",
      "[192]\ttrain-mlogloss:1.48276\teval-mlogloss:2.23705\n",
      "[193]\ttrain-mlogloss:1.47996\teval-mlogloss:2.23679\n",
      "[194]\ttrain-mlogloss:1.47697\teval-mlogloss:2.23669\n",
      "[195]\ttrain-mlogloss:1.47426\teval-mlogloss:2.23671\n",
      "[196]\ttrain-mlogloss:1.47147\teval-mlogloss:2.23671\n",
      "[197]\ttrain-mlogloss:1.46878\teval-mlogloss:2.23653\n",
      "[198]\ttrain-mlogloss:1.46565\teval-mlogloss:2.23639\n",
      "[199]\ttrain-mlogloss:1.46324\teval-mlogloss:2.23632\n",
      "[200]\ttrain-mlogloss:1.46059\teval-mlogloss:2.23624\n",
      "[201]\ttrain-mlogloss:1.45838\teval-mlogloss:2.23613\n",
      "[202]\ttrain-mlogloss:1.45597\teval-mlogloss:2.23593\n",
      "[203]\ttrain-mlogloss:1.45318\teval-mlogloss:2.23561\n",
      "[204]\ttrain-mlogloss:1.45048\teval-mlogloss:2.23574\n",
      "[205]\ttrain-mlogloss:1.44763\teval-mlogloss:2.23551\n",
      "[206]\ttrain-mlogloss:1.44529\teval-mlogloss:2.23546\n",
      "[207]\ttrain-mlogloss:1.44263\teval-mlogloss:2.23534\n",
      "[208]\ttrain-mlogloss:1.44002\teval-mlogloss:2.23529\n",
      "[209]\ttrain-mlogloss:1.43752\teval-mlogloss:2.23523\n",
      "[210]\ttrain-mlogloss:1.43494\teval-mlogloss:2.23517\n",
      "[211]\ttrain-mlogloss:1.43233\teval-mlogloss:2.2351\n",
      "[212]\ttrain-mlogloss:1.43018\teval-mlogloss:2.23502\n",
      "[213]\ttrain-mlogloss:1.42779\teval-mlogloss:2.23496\n",
      "[214]\ttrain-mlogloss:1.42539\teval-mlogloss:2.23485\n",
      "[215]\ttrain-mlogloss:1.42276\teval-mlogloss:2.23479\n",
      "[216]\ttrain-mlogloss:1.42044\teval-mlogloss:2.2346\n",
      "[217]\ttrain-mlogloss:1.41786\teval-mlogloss:2.23452\n",
      "[218]\ttrain-mlogloss:1.41526\teval-mlogloss:2.2345\n",
      "[219]\ttrain-mlogloss:1.41261\teval-mlogloss:2.23445\n",
      "[220]\ttrain-mlogloss:1.41051\teval-mlogloss:2.23437\n",
      "[221]\ttrain-mlogloss:1.40785\teval-mlogloss:2.23444\n",
      "[222]\ttrain-mlogloss:1.40525\teval-mlogloss:2.23427\n",
      "[223]\ttrain-mlogloss:1.40263\teval-mlogloss:2.2342\n",
      "[224]\ttrain-mlogloss:1.40017\teval-mlogloss:2.23423\n",
      "[225]\ttrain-mlogloss:1.3976\teval-mlogloss:2.23419\n",
      "[226]\ttrain-mlogloss:1.39523\teval-mlogloss:2.23413\n",
      "[227]\ttrain-mlogloss:1.39251\teval-mlogloss:2.23415\n",
      "[228]\ttrain-mlogloss:1.38987\teval-mlogloss:2.23395\n",
      "[229]\ttrain-mlogloss:1.38713\teval-mlogloss:2.23386\n",
      "[230]\ttrain-mlogloss:1.38483\teval-mlogloss:2.23378\n",
      "[231]\ttrain-mlogloss:1.38217\teval-mlogloss:2.2335\n",
      "[232]\ttrain-mlogloss:1.37975\teval-mlogloss:2.2335\n",
      "[233]\ttrain-mlogloss:1.37716\teval-mlogloss:2.23347\n",
      "[234]\ttrain-mlogloss:1.3747\teval-mlogloss:2.23332\n",
      "[235]\ttrain-mlogloss:1.37258\teval-mlogloss:2.23326\n",
      "[236]\ttrain-mlogloss:1.36995\teval-mlogloss:2.23324\n",
      "[237]\ttrain-mlogloss:1.36769\teval-mlogloss:2.23327\n",
      "[238]\ttrain-mlogloss:1.36558\teval-mlogloss:2.23325\n",
      "[239]\ttrain-mlogloss:1.3633\teval-mlogloss:2.23313\n",
      "[240]\ttrain-mlogloss:1.36111\teval-mlogloss:2.23311\n",
      "[241]\ttrain-mlogloss:1.35865\teval-mlogloss:2.23291\n",
      "[242]\ttrain-mlogloss:1.35642\teval-mlogloss:2.23289\n",
      "[243]\ttrain-mlogloss:1.35409\teval-mlogloss:2.23299\n",
      "[244]\ttrain-mlogloss:1.35171\teval-mlogloss:2.23285\n",
      "[245]\ttrain-mlogloss:1.34974\teval-mlogloss:2.23279\n",
      "[246]\ttrain-mlogloss:1.34746\teval-mlogloss:2.23263\n",
      "[247]\ttrain-mlogloss:1.34483\teval-mlogloss:2.23257\n",
      "[248]\ttrain-mlogloss:1.34265\teval-mlogloss:2.23261\n",
      "[249]\ttrain-mlogloss:1.3404\teval-mlogloss:2.23263\n",
      "[250]\ttrain-mlogloss:1.33784\teval-mlogloss:2.23266\n",
      "[251]\ttrain-mlogloss:1.33573\teval-mlogloss:2.23263\n",
      "[252]\ttrain-mlogloss:1.33352\teval-mlogloss:2.23261\n",
      "[253]\ttrain-mlogloss:1.33086\teval-mlogloss:2.23262\n",
      "[254]\ttrain-mlogloss:1.32892\teval-mlogloss:2.23249\n",
      "[255]\ttrain-mlogloss:1.32647\teval-mlogloss:2.23236\n",
      "[256]\ttrain-mlogloss:1.32424\teval-mlogloss:2.2323\n",
      "[257]\ttrain-mlogloss:1.32204\teval-mlogloss:2.23233\n",
      "[258]\ttrain-mlogloss:1.3197\teval-mlogloss:2.23237\n",
      "[259]\ttrain-mlogloss:1.31743\teval-mlogloss:2.23243\n",
      "[260]\ttrain-mlogloss:1.31512\teval-mlogloss:2.23255\n",
      "[261]\ttrain-mlogloss:1.31304\teval-mlogloss:2.2324\n",
      "[262]\ttrain-mlogloss:1.31082\teval-mlogloss:2.23235\n",
      "[263]\ttrain-mlogloss:1.30862\teval-mlogloss:2.23233\n",
      "[264]\ttrain-mlogloss:1.30619\teval-mlogloss:2.23225\n",
      "[265]\ttrain-mlogloss:1.30397\teval-mlogloss:2.23203\n",
      "[266]\ttrain-mlogloss:1.30165\teval-mlogloss:2.23205\n",
      "[267]\ttrain-mlogloss:1.29905\teval-mlogloss:2.23209\n",
      "[268]\ttrain-mlogloss:1.29689\teval-mlogloss:2.23194\n",
      "[269]\ttrain-mlogloss:1.29468\teval-mlogloss:2.232\n",
      "[270]\ttrain-mlogloss:1.2925\teval-mlogloss:2.23201\n",
      "[271]\ttrain-mlogloss:1.29044\teval-mlogloss:2.232\n",
      "[272]\ttrain-mlogloss:1.2882\teval-mlogloss:2.23204\n",
      "[273]\ttrain-mlogloss:1.28578\teval-mlogloss:2.23203\n",
      "[274]\ttrain-mlogloss:1.28349\teval-mlogloss:2.23201\n",
      "[275]\ttrain-mlogloss:1.28125\teval-mlogloss:2.23201\n",
      "[276]\ttrain-mlogloss:1.27905\teval-mlogloss:2.23194\n",
      "[277]\ttrain-mlogloss:1.27682\teval-mlogloss:2.23192\n",
      "[278]\ttrain-mlogloss:1.2745\teval-mlogloss:2.23185\n",
      "[279]\ttrain-mlogloss:1.27241\teval-mlogloss:2.23195\n",
      "[280]\ttrain-mlogloss:1.27031\teval-mlogloss:2.23196\n",
      "[281]\ttrain-mlogloss:1.26791\teval-mlogloss:2.23194\n",
      "[282]\ttrain-mlogloss:1.26608\teval-mlogloss:2.23205\n",
      "[283]\ttrain-mlogloss:1.26383\teval-mlogloss:2.23192\n",
      "[284]\ttrain-mlogloss:1.26166\teval-mlogloss:2.23195\n",
      "[285]\ttrain-mlogloss:1.25956\teval-mlogloss:2.23196\n",
      "[286]\ttrain-mlogloss:1.25734\teval-mlogloss:2.23207\n",
      "[287]\ttrain-mlogloss:1.25502\teval-mlogloss:2.23212\n",
      "[288]\ttrain-mlogloss:1.25294\teval-mlogloss:2.23208\n",
      "[289]\ttrain-mlogloss:1.25089\teval-mlogloss:2.23204\n",
      "[290]\ttrain-mlogloss:1.24886\teval-mlogloss:2.23212\n",
      "[291]\ttrain-mlogloss:1.24675\teval-mlogloss:2.23205\n",
      "[292]\ttrain-mlogloss:1.24466\teval-mlogloss:2.23212\n",
      "[293]\ttrain-mlogloss:1.24272\teval-mlogloss:2.23212\n",
      "[294]\ttrain-mlogloss:1.24072\teval-mlogloss:2.23205\n",
      "[295]\ttrain-mlogloss:1.23873\teval-mlogloss:2.23203\n",
      "[296]\ttrain-mlogloss:1.23648\teval-mlogloss:2.23209\n",
      "[297]\ttrain-mlogloss:1.2346\teval-mlogloss:2.23215\n",
      "[298]\ttrain-mlogloss:1.23244\teval-mlogloss:2.23223\n",
      "Stopping. Best iteration:\n",
      "[278]\ttrain-mlogloss:1.2745\teval-mlogloss:2.23185\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_boost_round = 500\n",
    "early_stopping_rounds = 20\n",
    "\n",
    "watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "gbm = xgb.train(params, dtrain, num_boost_round, evals=watchlist, early_stopping_rounds=early_stopping_rounds, verbose_eval=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "from operator import itemgetter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = gbm.predict(xgb.DMatrix(X_test), ntree_limit=gbm.best_iteration)\n",
    "score = log_loss(y_test.tolist(), check)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2319156743681585"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.08784404, 0.09220483, 0.08801607, ..., 0.06259472, 0.03711446,\n",
       "        0.1079703 ],\n",
       "       [0.06693178, 0.09951708, 0.04880673, ..., 0.10991641, 0.17635462,\n",
       "        0.0778167 ],\n",
       "       [0.16810164, 0.10479507, 0.0337332 , ..., 0.03698546, 0.02294733,\n",
       "        0.05093664],\n",
       "       ...,\n",
       "       [0.20034032, 0.12633209, 0.02792231, ..., 0.02415054, 0.01440627,\n",
       "        0.05381081],\n",
       "       [0.08347673, 0.04599396, 0.02508026, ..., 0.05307839, 0.25855115,\n",
       "        0.03921349],\n",
       "       [0.05790641, 0.05077343, 0.06321309, ..., 0.16123024, 0.19609578,\n",
       "        0.08253209]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_map(features):\n",
    "    outfile = open('xgb.fmap', 'w')\n",
    "    for i, feat in enumerate(features):\n",
    "        outfile.write('{0}\\t{1}\\tq\\n'.format(i, feat))\n",
    "    outfile.close()\n",
    "\n",
    "\n",
    "def get_importance(gbm, features):\n",
    "    create_feature_map(features)\n",
    "    importance = gbm.get_fscore(fmap='xgb.fmap')\n",
    "    importance = sorted(importance.items(), key=itemgetter(1), reverse=True)\n",
    "    return importance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = get_importance(gbm, magyarazo_valtozok)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('events_per_day', 9265),\n",
       " ('device_model', 8950),\n",
       " ('label_i_22222', 5569),\n",
       " ('label_22222', 5383),\n",
       " ('phone_brand_eng', 4878),\n",
       " ('label_i_179', 4634),\n",
       " ('label_i_721', 4614),\n",
       " ('label_i_128', 4510),\n",
       " ('label_i_714', 4188),\n",
       " ('label_i_306', 4059),\n",
       " ('label_548', 3887),\n",
       " ('label_i_303', 3818),\n",
       " ('label_i_710', 3779),\n",
       " ('label_i_713', 3774),\n",
       " ('label_i_794', 3765),\n",
       " ('label_i_549', 3568),\n",
       " ('label_i_178', 3468),\n",
       " ('label_i_548', 3464),\n",
       " ('label_713', 3436),\n",
       " ('label_i_302', 3411),\n",
       " ('label_549', 3410),\n",
       " ('label_721', 3339),\n",
       " ('label_302', 3261),\n",
       " ('label_i_1014', 3255),\n",
       " ('label_306', 3249),\n",
       " ('label_i_1003', 3246),\n",
       " ('label_i_251', 3239),\n",
       " ('events_num', 3223),\n",
       " ('label_i_172', 3211),\n",
       " ('label_i_704', 3200),\n",
       " ('label_i_168', 3190),\n",
       " ('label_i_724', 3185),\n",
       " ('label_i_723', 3058),\n",
       " ('label_704', 3047),\n",
       " ('label_303', 3009),\n",
       " ('label_i_262', 3008),\n",
       " ('label_i_720', 2936),\n",
       " ('label_i_405', 2912),\n",
       " ('label_179', 2876),\n",
       " ('label_128', 2836),\n",
       " ('label_714', 2800),\n",
       " ('label_178', 2749),\n",
       " ('label_i_783', 2655),\n",
       " ('label_i_1012', 2627),\n",
       " ('label_i_252', 2573),\n",
       " ('label_i_263', 2571),\n",
       " ('label_i_1007', 2534),\n",
       " ('label_i_730', 2521),\n",
       " ('label_172', 2509),\n",
       " ('label_710', 2458),\n",
       " ('label_263', 2448),\n",
       " ('label_i_256', 2424),\n",
       " ('label_252', 2368),\n",
       " ('label_168', 2363),\n",
       " ('label_i_775', 2340),\n",
       " ('label_i_1008', 2310),\n",
       " ('label_i_786', 2262),\n",
       " ('label_723', 2243),\n",
       " ('label_i_909', 2218),\n",
       " ('label_i_564', 2217),\n",
       " ('label_1003', 2153),\n",
       " ('label_i_756', 2150),\n",
       " ('label_i_959', 2085),\n",
       " ('label_251', 2039),\n",
       " ('label_794', 2011),\n",
       " ('label_405', 2001),\n",
       " ('label_i_780', 1931),\n",
       " ('label_724', 1910),\n",
       " ('label_1014', 1880),\n",
       " ('label_i_253', 1864),\n",
       " ('label_1007', 1853),\n",
       " ('label_i_761', 1812),\n",
       " ('label_i_782', 1812),\n",
       " ('label_262', 1779),\n",
       " ('label_i_781', 1704),\n",
       " ('label_i_751', 1640),\n",
       " ('label_783', 1562),\n",
       " ('label_i_406', 1540),\n",
       " ('label_i_777', 1535),\n",
       " ('label_959', 1534),\n",
       " ('label_775', 1506),\n",
       " ('label_720', 1448),\n",
       " ('label_i_932', 1419),\n",
       " ('label_i_773', 1388),\n",
       " ('label_i_779', 1361),\n",
       " ('label_i_1015', 1361),\n",
       " ('label_i_254', 1352),\n",
       " ('label_730', 1316),\n",
       " ('label_786', 1295),\n",
       " ('label_i_752', 1295),\n",
       " ('label_256', 1268),\n",
       " ('label_756', 1267),\n",
       " ('label_1012', 1260),\n",
       " ('label_i_691', 1243),\n",
       " ('label_909', 1116),\n",
       " ('label_i_757', 1109),\n",
       " ('label_i_787', 1102),\n",
       " ('label_i_759', 1098),\n",
       " ('label_1008', 1088),\n",
       " ('label_782', 1036),\n",
       " ('label_i_758', 1014),\n",
       " ('label_761', 1004),\n",
       " ('label_253', 1003),\n",
       " ('label_i_562', 998),\n",
       " ('label_780', 968),\n",
       " ('label_691', 920),\n",
       " ('label_406', 866),\n",
       " ('label_781', 848),\n",
       " ('label_564', 830),\n",
       " ('label_779', 781),\n",
       " ('label_751', 733),\n",
       " ('label_777', 675),\n",
       " ('label_932', 641),\n",
       " ('label_773', 554),\n",
       " ('label_254', 545),\n",
       " ('label_i_960', 499),\n",
       " ('label_757', 476),\n",
       " ('label_1015', 447),\n",
       " ('label_752', 428),\n",
       " ('label_i_407', 427),\n",
       " ('label_787', 417),\n",
       " ('label_759', 410),\n",
       " ('label_960', 395),\n",
       " ('label_758', 366),\n",
       " ('label_562', 322),\n",
       " ('label_407', 209)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn.cross_validation'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-c98bc626ba7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_validation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn.cross_validation'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cross_val_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-746f0556d06c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgbm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'f1_weighted'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cross_val_score' is not defined"
     ]
    }
   ],
   "source": [
    "cross_val_score(estimator=gbm,X=X_test,y=Y_test,scoring='f1_weighted',cv=5)\n",
    "print (classification_report(y_true=Y_test,y_pred=gb.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.08784404, 0.09220483, 0.08801607, ..., 0.06259472, 0.03711446,\n",
       "        0.1079703 ],\n",
       "       [0.06693178, 0.09951708, 0.04880673, ..., 0.10991641, 0.17635462,\n",
       "        0.0778167 ],\n",
       "       [0.16810164, 0.10479507, 0.0337332 , ..., 0.03698546, 0.02294733,\n",
       "        0.05093664],\n",
       "       ...,\n",
       "       [0.20034032, 0.12633209, 0.02792231, ..., 0.02415054, 0.01440627,\n",
       "        0.05381081],\n",
       "       [0.08347673, 0.04599396, 0.02508026, ..., 0.05307839, 0.25855115,\n",
       "        0.03921349],\n",
       "       [0.05790641, 0.05077343, 0.06321309, ..., 0.16123024, 0.19609578,\n",
       "        0.08253209]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
